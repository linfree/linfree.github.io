{"meta":{"title":"静思地","subtitle":null,"description":null,"author":"Lin Free","url":"http://blog.fbi.st"},"pages":[{"title":"about","date":"2017-06-01T14:08:54.000Z","updated":"2019-12-26T09:35:23.353Z","comments":true,"path":"about/index.html","permalink":"http://blog.fbi.st/about/index.html","excerpt":"好好生活，天天向上！布局先做好，内容慢慢填。","text":"好好生活，天天向上！布局先做好，内容慢慢填。"},{"title":"categories","date":"2017-06-01T14:28:43.000Z","updated":"2019-12-26T09:35:23.359Z","comments":true,"path":"categories/index.html","permalink":"http://blog.fbi.st/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"一段优雅的高级正则打开[断言]之门","slug":"一段优雅的高级正则打开[断言]之门","date":"2019-10-10T15:32:52.000Z","updated":"2019-12-27T04:38:04.902Z","comments":true,"path":"2019/10/10/一段优雅的高级正则打开[断言]之门/","link":"","permalink":"http://blog.fbi.st/2019/10/10/一段优雅的高级正则打开[断言]之门/","excerpt":"起因技术群里的群友又提出这样一个问题： 能用一个正则表达式，来判断一个密码是否即包含数字，又包含字母，且长度至少为6位吗？","text":"起因技术群里的群友又提出这样一个问题： 能用一个正则表达式，来判断一个密码是否即包含数字，又包含字母，且长度至少为6位吗？ 分析问题 长度要6位。（可能用到{6,}限制长度） 必须要有数字。 （可能要\\d,[0-9]) 必须要有字母。 （可能要[A-Za-z]） 思考如果这个问题要是用php或者py代码验证都非常简单。几个if就解决了。 （可能 但是要求一个正则解决。难道要用正则的if？正则有if吗？？ 一查还真有！ 正则if then else正向先行断言的形式1(?(?=regex)then|else) 解释是： 如果满足正则regex匹配成功，则必须匹配then部分，否则匹配else部分。四种断言形式都可以使用。 举个栗子： 1^(?(?=(\\d&#123;6,&#125;))\\d*|1)$ 当满足\\d{6,}时，即大于六个以上数字的时候匹配\\d*，即全部是数字。不满足\\d{6,}时，匹配数字1. 正向后行断言的形式该表达式，如果前面是regex的话，匹配后面的then，否则匹配else1(?(?&lt;=regex)then|else) 正则断言if else似乎还是不能优雅的解决问题。但是抛出一个新概念：断言。 正则断言包括 零宽：只匹配位置，在匹配过程中，不占用字符，所以被称为零宽 先行：正则引擎在扫描字符的时候，从左往右扫描，匹配扫描指针未扫描过的字符，先于指针，故称先行 后行：匹配指针已扫描过的字符，后于指针到达该字符，故称后行，即产生回溯 正向：即匹配括号中的表达式 负向：不匹配括号中的表达式 零宽断言零宽正向先行断言，又称正向向前查找（positive lookhead）(?=pattern)：某位置后面紧接着的字符序列要匹配 pattern 例：12`sinM.`.match(/sin(?=M\\.)/g); // [\"sin\"]`M.sin`.match(/sin(?=M\\.)/g); // null 第一个 sin 会匹配，因为他后面有 pattern 一个优雅的解最后,综合一下思路的几个正则段，正则小王子给出这样的一个答案：1^.*(?=.&#123;6,&#125;)(?=.*\\d)(?=.*[A-Za-z]).*$ 真漂亮。","categories":[{"name":"php","slug":"php","permalink":"http://blog.fbi.st/categories/php/"}],"tags":[{"name":"php","slug":"php","permalink":"http://blog.fbi.st/tags/php/"}]},{"title":"匹配IPv4的最强正则","slug":"匹配IPv4的最强正则","date":"2019-10-09T13:52:02.000Z","updated":"2019-12-27T04:40:47.965Z","comments":true,"path":"2019/10/09/匹配IPv4的最强正则/","link":"","permalink":"http://blog.fbi.st/2019/10/09/匹配IPv4的最强正则/","excerpt":"起因技术群里的群友提出这样一个问题： php里面，能够有效匹配任意一个正常输入的ipv4地址，最短的正则表达式是什么？","text":"起因技术群里的群友提出这样一个问题： php里面，能够有效匹配任意一个正常输入的ipv4地址，最短的正则表达式是什么？ 问题分析 ip地址范围是0.0.0.0 - 255.255.255.255 除非是0，不能以0开头 前面三个有点,末尾不能有点 解决方案虽然php有自己判断ip的函数，但问题是用正则表达式解决。 方案1(群友方案)简单的匹配1\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125; 存在问题：999.999.999.999都能匹配到。 方案2(群友方案)1^(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.)&#123;3&#125;(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)$ 存在问题：虽然数字范围限制在255以内，但是001.1.1.1也能匹配到。 方案三（我的方案）1^(\\d|[1-9][0-9]|1\\d&#123;2&#125;|2[0-4]\\d|25[0-5])(\\.(\\d|[1-9][0-9]|1\\d&#123;2&#125;|2[0-4]\\d|25[0-5]))&#123;3&#125;$ 存在问题：能满足所有的ip情况，但是不够优雅，简洁。算不上是最强。 最强ipv4表达式(之一吧)1/^((2[0-4]|1\\d|[1-9])?\\d|25[0-5])(\\.(?1))&#123;3&#125;\\z/ 简洁优雅。🐂！","categories":[{"name":"php","slug":"php","permalink":"http://blog.fbi.st/categories/php/"}],"tags":[{"name":"php","slug":"php","permalink":"http://blog.fbi.st/tags/php/"}]},{"title":"elasticsearch常用查询整理","slug":"elasticsearch常用查询整理","date":"2019-07-19T06:06:32.000Z","updated":"2019-12-26T10:05:39.303Z","comments":true,"path":"2019/07/19/elasticsearch常用查询整理/","link":"","permalink":"http://blog.fbi.st/2019/07/19/elasticsearch常用查询整理/","excerpt":"1. 结构话查询（Structured search）1.1 精确查询（term）最为常用的 term 查询， 可以用它处理数字（numbers）、布尔值（Booleans）、日期（dates）以及文本（text）。 12345&#123; \"term\" : &#123; \"price\" : 20 &#125;&#125; 类似sql的123SELECT documentFROM productsWHERE price = 20","text":"1. 结构话查询（Structured search）1.1 精确查询（term）最为常用的 term 查询， 可以用它处理数字（numbers）、布尔值（Booleans）、日期（dates）以及文本（text）。 12345&#123; \"term\" : &#123; \"price\" : 20 &#125;&#125; 类似sql的123SELECT documentFROM productsWHERE price = 20 1.2 查找多个精确值（terms）12345&#123; \"terms\" : &#123; \"price\" : [20, 30] &#125;&#125; 1.3 范围查询(range)123456\"range\" : &#123; \"price\" : &#123; \"gte\" : 20, \"lte\" : 40 &#125;&#125; 类似sql的在 SQL 中，范围查询可以表示为：123SELECT documentFROM productsWHERE price BETWEEN 20 AND 40 2.全文检索（full-text search）2.1 match查询（match）查询搜索全文字段中的单个词或多个词 12345678GET /my_index/my_type/_search&#123; \"query\": &#123; \"match\": &#123; \"title\": \"QUICK!\" &#125; &#125;&#125; 2.2 match链接符（operator)match 查询的结构需要做稍许调整才能使用 operator 操作符参数。下面查询会查找BROWN和DOG同时存在的doc1234567891011GET /my_index/my_type/_search&#123; \"query\": &#123; \"match\": &#123; \"title\": &#123; \"query\": \"BROWN DOG!\", \"operator\": \"and\" &#125; &#125; &#125;&#125; 2.3 组合查询（bool）12345678910111213GET /my_index/my_type/_search&#123; \"query\": &#123; \"bool\": &#123; \"must\": &#123; \"match\": &#123; \"title\": \"quick\" &#125;&#125;, \"must_not\": &#123; \"match\": &#123; \"title\": \"lazy\" &#125;&#125;, \"should\": [ &#123; \"match\": &#123; \"title\": \"brown\" &#125;&#125;, &#123; \"match\": &#123; \"title\": \"dog\" &#125;&#125; ] &#125; &#125;&#125; 2.4 多字段查询（multi_match）多匹配查询的类型有多种： best_fields 、 most_fields 和 cross_fields （最佳字段、多数字段、跨字段） 默认情况下，查询的类型是 best_fields ，这表示它会为每个字段生成一个 match 查询，然后将它们组合到 dis_max 查询的内部，如下：1234567891011121314151617181920212223&#123; \"dis_max\": &#123; \"queries\": [ &#123; \"match\": &#123; \"title\": &#123; \"query\": \"Quick brown fox\", \"minimum_should_match\": \"30%\" &#125; &#125; &#125;, &#123; \"match\": &#123; \"body\": &#123; \"query\": \"Quick brown fox\", \"minimum_should_match\": \"30%\" &#125; &#125; &#125;, ], \"tie_breaker\": 0.3 &#125;&#125; 上面这个查询用 multi_match 重写成更简洁的形式：123456789&#123; \"multi_match\": &#123; \"query\": \"Quick brown fox\", \"type\": \"best_fields\", \"fields\": [ \"title\", \"body\" ], \"tie_breaker\": 0.3, \"minimum_should_match\": \"30%\" &#125;&#125; best_fields 类型是默认值，可以不指定。 还可以模糊字段123456&#123; \"multi_match\": &#123; \"query\": \"Quick brown fox\", \"fields\": \"*_title\" &#125;&#125; 2.5 短语匹配（match_phrase ）12345678GET /my_index/my_type/_search&#123; \"query\": &#123; \"match_phrase\": &#123; \"title\": \"quick brown fox\" &#125; &#125;&#125; 什么是短语一个被认定为和短语 quick brown fox 匹配的文档，必须满足以下这些要求： &gt; quick 、 brown 和 fox 需要全部出现在域中。 brown 的位置应该比 quick 的位置大 1 。 fox 的位置应该比 quick 的位置大 2 。 如果以上任何一个选项不成立，则该文档不能认定为匹配 2.6 前缀查询(prefix)12345678GET /my_index/address/_search&#123; \"query\": &#123; \"prefix\": &#123; \"postcode\": \"W1\" &#125; &#125;&#125; 为了支持前缀匹配，查询会做以下事情： 扫描词列表并查找到第一个以 W1 开始的词。 搜集关联的文档 ID 。 *移动到下一个词。 如果这个词也是以 W1 开头，查询跳回到第二步再重复执行，直到下一个词不以 W1 为止。 2.7 通配符查询（wildcard） wildcard 通配符查询也是一种底层基于词的查询，与前缀查询不同的是它允许指定匹配的正则式。它使用标准的 shell 通配符查询： ? 匹配任意字符， * 匹配 0 或多个字符12345678GET /my_index/address/_search&#123; \"query\": &#123; \"wildcard\": &#123; \"postcode\": \"W?F*HW\" &#125; &#125;&#125; 2.8 正则查询（regexp）12345678GET /my_index/address/_search&#123; \"query\": &#123; \"regexp\": &#123; \"postcode\": \"W[0-9].+\" &#125; &#125;&#125; prefix 、 wildcard 和 regexp 查询是基于词操作的，如果用它们来查询 analyzed 字段，它们会检查字段里面的每个词，而不是将字段作为整体来处理。 比方说包含 “Quick brown fox” （快速的棕色狐狸）的 title 字段会生成词： quick 、 brown 和 fox 3.query_string3.1 query_stringtitle字段包含crime，且权重为10，也要包含punishment，但是otitle不包含cat，同时author字段包含Fyodor和dostoevsky。 12345678&#123; \"query\": &#123; \"query_string\": &#123; \"query\":\"title:crime^10 +title:punishment -otitle:cat +author:(+Fyodor +dostoevsky)\", \"default_field\":\"title\" &#125; &#125;&#125; 常见query_string写法常见写法： name字段为obama12345&#123; \"query\": &#123; \"query_string\": \"name:obama\" &#125;&#125; 存在一个nam开头的字段，值为obama12345&#123; \"query\": &#123; \"query_string\": \"nam\\\\*:obama\" &#125;&#125; name字段值为null的文档 12345&#123; \"query\": &#123; \"query_string\": \"__missing__:name\" &#125;&#125; name字段值不为null的文档12345&#123; \"query\": &#123; \"query_string\": \"__exists__:name\" &#125;&#125; name字段为Obama或者xidada的文档 12345&#123; \"query\": &#123; \"query_string\": \"name:（obama OR xidada)\" &#125;&#125; Wildcardsquery的内容中支持？与* ？可以代替一个任意字符、*可代表任意个字符（包括零个）。比如你要查询的内容很长，记不清了但是你记得末尾是tor，那么你只需要把query内容写成*tor即可 正则如果要在query的内容中使用正则表达式，在两端加上正斜杠/即可。比如name:/ob[am]{2}a/ 3.2 simple_query_string查询解析出错时不抛异常，丢弃查询无效的部分 12345678&#123; \"query\": &#123; \"simple_query_string\": &#123; \"query\":\"title:crime^10 +title:punishment -otitle:cat +author:(+Fyodor +dostoevsky)\", \"default_operator\":\"or\" &#125; &#125;&#125; 3.3 标识符查询12345678&#123; \"query\": &#123; \"ids\": &#123; \"type\":\"book\", \"values\":[\"1\",\"2\",\"3\"] &#125; &#125;&#125; tipsbool查询的1234567891011121314151617181920GET test*/_search&#123; \"size\":3, \"query\": &#123; \"bool\":&#123; \"must\": [ &#123;\"match\":&#123;\"message\": \"学生\"&#125;&#125;, &#123;\"match\":&#123;\"message\": \"所有\"&#125;&#125; ], \"should\": [ &#123;\"match\": &#123;\"port\": \"53198\"&#125;&#125;, &#123;\"match\": &#123;\"@timestamp\":\"2018-09-17T17:49:25.991Z\"&#125;&#125; ], \"must_not\": [ &#123;\"match\": &#123;\"port\": \"64273\"&#125;&#125;, &#123;\"match\": &#123;\"port\":\"1234\"&#125;&#125; ] &#125; &#125;&#125; 等价于12345678GET test*/_search&#123; \"size\":3, \"query\": &#123; \"query_string\":&#123;\"query\": \"message:学生 +message:所有 -port:55714\"&#125; &#125;&#125;","categories":[{"name":"Elasticsearch非权威指南","slug":"Elasticsearch非权威指南","permalink":"http://blog.fbi.st/categories/Elasticsearch非权威指南/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://blog.fbi.st/tags/Elasticsearch/"}]},{"title":"《如何阅读一本书》读书笔记","slug":"《如何阅读一本书》读书笔记","date":"2019-06-20T13:13:12.000Z","updated":"2019-12-26T08:50:05.455Z","comments":true,"path":"2019/06/20/《如何阅读一本书》读书笔记/","link":"","permalink":"http://blog.fbi.st/2019/06/20/《如何阅读一本书》读书笔记/","excerpt":"《如何阅读一本书》 简介每本书的封面之下都有一套自己的骨架，作为一个分析阅读的读者，责任就是要找出这个骨架。 一本书出现在面前时，肌肉包着骨头，衣服包裹着肌肉，可说是盛装而来。 读者用不着揭开它的外衣或是撕去它的肌肉来得到在柔软表皮下的那套骨架，但是一定要用一双X光般的透视眼来看这本书，因为那是了解一本书、掌握其骨架的基础。 《如何阅读一本书》初版于1940年，1972年大幅增订改写为新版。 懂阅读的人，初探阅读的人，读这本书可以少走冤枉路。对阅读有所体会的人，读这本书可以有更深的印证和领悟。 (来自豆瓣)","text":"《如何阅读一本书》 简介每本书的封面之下都有一套自己的骨架，作为一个分析阅读的读者，责任就是要找出这个骨架。 一本书出现在面前时，肌肉包着骨头，衣服包裹着肌肉，可说是盛装而来。 读者用不着揭开它的外衣或是撕去它的肌肉来得到在柔软表皮下的那套骨架，但是一定要用一双X光般的透视眼来看这本书，因为那是了解一本书、掌握其骨架的基础。 《如何阅读一本书》初版于1940年，1972年大幅增订改写为新版。 懂阅读的人，初探阅读的人，读这本书可以少走冤枉路。对阅读有所体会的人，读这本书可以有更深的印证和领悟。 (来自豆瓣) 作者简介莫提默·J. 艾德勒（1902－2001）以学者、教育家、编辑人等多重面貌享有盛名。除了写作《如何阅读一本书》外，以主编《西方世界的经典人并担任1974年第十五版《大英百科全书》的编辑相异而闻名于世。 查尔斯·范多伦（1926－）先曾任美国哥伦比亚大学教授。后因故离任，和艾德勒一起工作。一方面襄助艾德勒编辑《大英百科全书》，一方面将本书1940年初版内容大幅度增补改写。 读书有感为什么从这本书开始？工欲善其事，必先利其器。所以读书之前，读一本优秀的教人读书的书，是非常有必要的。《如何阅读一本书》正是一本这样的好书。 看完这本书后，相信许多人都会像我一样，懊悔自己没有在更早的时候接触到它。认识自己的阅读方式，然后使用更科学和有效的方式去阅读。 因为本人认为他是一本很好的书（当然，本书的优秀不需要我的肯定），同时他能让我们收获阅读的方法和对阅读的理解。看完这本书后，我真的希望有人能在更早的时候推荐我阅读这本书。所以我打算从这本书开始。 看本书前我是怎么阅读？首先，在看本书之前，我应该已经算是一个书中说的“阅读的人”, 但同时我也是一个不太懂得阅读的人。 我是个小说迷，看小说时整个人都很轻松，正因为这种轻松的感觉，让我很多时候都不能自拔；我很喜欢看一些科普读物，让我的视野更宽广；因为工作需求，我也会看很多技术的书籍充电；因为好奇心很大，所以经常还会翻阅各种各样的‘杂书’； 但在阅读本书之前，我一直都没有自己的一个很合理的阅读方法，也不了解自己阅读行为的一些理论层的解释。例如：我经常以阅读小说的速度去阅读一些技术书籍，往往不得其解，随之放弃。也很多时候沉迷于简单的小说阅读的快感中，还认为从中收获很多。 错误的阅读方式让我错过了去体会很多好书的精华，浪费了许多时间在一些不好的书上面。 我的收获是？这本书让我对阅读有了一个更加系统和科学的认识，也纠正了我一些不合适的阅读方式。 我们阅读书籍的目的在于获得新的资讯，从而让让我们获得成长。毫无疑问，我在这本书中收获了这些。 在看到本书开始大概三分之一的位置的时候，我有一种与本书相见恨晚的感觉，作者描述的阅读状态和方式，都很契合我的从前总结的阅读感受。随着更加往后的阅读，发现作者所讲的内容越来越难，我阅读的难度也在增加，这个时候，作者告诉我们：当你阅读越是困难，说明与作者的层次相差越大，阅读的收获也是越大。 随着整本书读完，做完后面的阅读测试题，才感受到作者对阅读的理解至深，有一种再看一遍的冲动。也有一种找本新书来应用本书收获的感觉。 这本书该怎么读？这本书我是花了近一个月早上早起，每天挤出半个小时来看完的。阅读作者阅读的数量和阅读涉及的领域之广，让我深深的钦佩。也是正是因为作者的博学，所以如果没有一定的知识储备，在阅读本书的时候还是会遇到一些困难的，当遇到这些困难的时候，就要像作者所说的：坚持看下去。这是一本偏向应用的书，所以我们在阅读的时候，更重要的还有要注重实践。在本书结尾的地方也留了一些阅读的测验。当然更多的还是需要在以后的更多的阅读活动中去实践。 用简短的话总结？本书从阅读的四个层次，循序深入的为我们解析了各个阅读阶段的技巧和注意事项。是一本指导阅读人阅读的很好的一本书。值得推荐。 阅读的人： 所谓‘阅读的人’，是指那些今天仍然习惯于从书写文字中汲取大量资讯，以增进对世界了解的人。","categories":[{"name":"read","slug":"read","permalink":"http://blog.fbi.st/categories/read/"}],"tags":[{"name":"生活","slug":"生活","permalink":"http://blog.fbi.st/tags/生活/"},{"name":"读书笔记","slug":"读书笔记","permalink":"http://blog.fbi.st/tags/读书笔记/"}]},{"title":"mysql通过触发器远程同步","slug":"mysql通过触发器远程同步","date":"2019-05-27T06:11:53.000Z","updated":"2019-12-26T10:08:26.134Z","comments":true,"path":"2019/05/27/mysql通过触发器远程同步/","link":"","permalink":"http://blog.fbi.st/2019/05/27/mysql通过触发器远程同步/","excerpt":"mysql通过触发器远程同步 约定： 需要同步的表为: A表 中间的表为: B表 同步到的远程表为: C表","text":"mysql通过触发器远程同步 约定： 需要同步的表为: A表 中间的表为: B表 同步到的远程表为: C表 一、检查mysql是否支持federated数据引擎1.查看开启的储存引擎1SHOW ENGINES; 2.如果不支持Support的值是NO| FEDERATED | NO | Federated MySQL storage engine | NULL | NULL | NULL | 可能需要修改mysql配置文件；若没有federated引擎需要配置my.cnf文件。123vim /usr/local/mysql/my.cnf``` 在`[mysqld]`后面直接加`federated`，并且注释掉`skip-federated`（前面加#） [mysqld]federated12345678910111213141516### 二、建立同步的federated表和远程的表&gt; ip示例如下：- 数据源： 192.168.1.1- Federated: 192.168.1.1- 远程： 192.168.1.156#### 原表数据结构如下：```sqlCREATE TABLE `test_20180425` ( `id` int(11) NOT NULL, `somthing` int(11) DEFAULT NULL,) ENGINE=MyISAM DEFAULT CHARSET=utf8; federated表1234CREATE TABLE `db_bak` ( `id` int(11) NOT NULL, `somthing` int(11) DEFAULT NULL,) ENGINE=FEDERATED DEFAULT CHARSET=utf8 CONNECTION='mysql://abc:abc123@192.168.1.156/remote_db/db_admin' 触发器123456789101112131415161718192021DELIMITER $$USE `db`$$DROP TRIGGER /*!50032 IF EXISTS */`t_db_admin_insert`$$CREATE /*!50017 DEFINER = 'root'@'%' */TRIGGER `t_db_admin_insert` AFTER INSERT ON `test_20180425` FOR EACH ROWBEGIN INSERT INTO db.`db_bak` ( `id`, `someting` )VALUES ( NEW.id, NEW.someting ) ;END ;$$DELIMITER ;","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.fbi.st/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.fbi.st/tags/MySQL/"}]},{"title":"leetcode算法题Z字形变换的解答","slug":"leetcode算法题Z字形变换的解答","date":"2019-04-20T08:07:31.000Z","updated":"2019-12-26T10:13:22.884Z","comments":true,"path":"2019/04/20/leetcode算法题Z字形变换的解答/","link":"","permalink":"http://blog.fbi.st/2019/04/20/leetcode算法题Z字形变换的解答/","excerpt":"题目内容如下将一个给定字符串根据给定的行数，以从上往下、从左到右进行 Z 字形排列。 比如输入字符串为 “LEETCODEISHIRING” 行数为 3 时，排列如下： 123L C I RE T O E S I I GE D H N 之后，你的输出需要从左往右逐行读取，产生出一个新的字符串，比如：&quot;LCIRETOESIIGEDHN&quot;。","text":"题目内容如下将一个给定字符串根据给定的行数，以从上往下、从左到右进行 Z 字形排列。 比如输入字符串为 “LEETCODEISHIRING” 行数为 3 时，排列如下： 123L C I RE T O E S I I GE D H N 之后，你的输出需要从左往右逐行读取，产生出一个新的字符串，比如：&quot;LCIRETOESIIGEDHN&quot;。 请你实现这个将字符串进行指定行数变换的函数：1string convert(string s, int numRows); 示例 1: 输入: s = &quot;LEETCODEISHIRING&quot;, numRows = 3 输出: &quot;LCIRETOESIIGEDHN&quot; 示例 2: 输入: s = &quot;LEETCODEISHIRING&quot;, numRows = 4 输出: &quot;LDREOEIIECIHNTSG&quot; 解释:1234L D RE O E I IE C I H NT S G 题目解答思路：明显的解决方案就是row个数组，然后循环切割字符串，row个数组里填。当最大的时候就往回-1,最小时候就+1,如此循环。当然，当row==1时候直接返回元字符串 解法1 123456789101112131415161718192021222324252627282930class Solution(object): def convert(self, s, numRows): \"\"\" :type s: str :type numRows: int :rtype: str \"\"\" tmp = &#123;&#125; z = 0 f = 0 if numRows == 1: print(s) return s for n in range(numRows): tmp[n] = [] for i in s: tmp[z].append(i) if f == 1: z -= 1 else: z += 1 if z == (numRows-1): f = 1 elif z == 0: f = 0 r = \"\" for t in tmp: r += \"\".join(tmp[t]) return r 这个解法的效率不高，思路不变，优化一下代码：1234567891011121314151617class Solution(object): def convert(self, s, numRows): \"\"\" :type s: str :type numRows: int :rtype: str \"\"\" z = 0 f = True if numRows == 1: return s tmp = [\"\" for i in range(numRows)] for i in s: tmp[z] += i if z == (numRows-1) or z == 0: f = not f z = z-1 if f else z+1 return \"\".join(tmp)","categories":[{"name":"leetcode","slug":"leetcode","permalink":"http://blog.fbi.st/categories/leetcode/"}],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://blog.fbi.st/tags/leetcode/"}]},{"title":"常用mysql命令笔记","slug":"常用mysql命令笔记","date":"2019-04-10T14:07:01.000Z","updated":"2019-12-26T10:14:38.048Z","comments":true,"path":"2019/04/10/常用mysql命令笔记/","link":"","permalink":"http://blog.fbi.st/2019/04/10/常用mysql命令笔记/","excerpt":"添加用户1CREATE USER zhangsan IDENTIFIED BY 'zhangsan'; 查看当前用户12SELECT USER();SELECT CURRENT_USER();","text":"添加用户1CREATE USER zhangsan IDENTIFIED BY 'zhangsan'; 查看当前用户12SELECT USER();SELECT CURRENT_USER(); 查看用户的权限123SHOW GRANTS FOR 你的用户;SHOW GRANTS FOR root@'localhost';SHOW GRANTS FOR webgametest@10.3.18.158; 重载权限表1FLUSH PRIVILEGES; 授权12GRANT ALL PRIVILEGES ON zhangsanDb.* TO zhangsan@'%' IDENTIFIED BY 'zhangsan';# FLUSH PRIVILEGES; 说明：除了“ALL PRIVILEGES”是所有权限外，还有常用的： SELECT ：读取权限。 DELETE ：删除权限。 UPDATE ：更新权限。 CREATE ：创建权限。 DROP ：删除数据库、数据表权限。 ###修改密码12UPDATE mysql.user SET password = PASSWORD('zhangsannew') WHERE user = 'zhangsan' AND HOST = '%';#FLUSH PRIVILEGES; 删除用户1DROP USER zhangsan@'%'; 导入数据123456# mysql 命令导入mysql -uroot -p123456 -Ddbname &lt; file.sql# source 命令导入数据库需要先登录到数库终端：source /home/abc/abc.sql # 导入备份数据库# load命令上传LOAD DATA LOCAL INFILE 'dump.txt' INTO TABLE mytbl FIELDS TERMINATED BY ':' LINES TERMINATED BY '\\r\\n'; 数据导出123456# 导出某个表mysqldump -u root -p DB table &gt; dump.txt# 导出某个库mysqldump -u root -p DB &gt; database_dump.txt# 导出所有数据库：mysqldump -u root -p --all-databases &gt; database_dump.txt 查看数据库的引擎1SHOW ENGINES; 创建数据库并指定编码1CREATE DATABASE IF NOT EXISTS my_db default charset utf8 COLLATE utf8_general_ci; 复制表(同一表结构)1CREATE TABLE IF NOT EXISTS teacher_his LIKE teacher ; 重命名表1ALTER TABLE t1 RENAME t2; 查看当前数据库的编码12USE DB;SHOW VARIABLES LIKE 'character_set_database'; 修改数据库的编码1ALTER DATABASE xxx CHARACTER SET gb2312;","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.fbi.st/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.fbi.st/tags/MySQL/"}]},{"title":"巧用cat命令快速的拼接大量txt文件","slug":"巧用cat命令快速的拼接大量txt文件","date":"2019-02-19T13:03:16.000Z","updated":"2019-12-27T09:53:46.523Z","comments":true,"path":"2019/02/19/巧用cat命令快速的拼接大量txt文件/","link":"","permalink":"http://blog.fbi.st/2019/02/19/巧用cat命令快速的拼接大量txt文件/","excerpt":"遇到问题记得很久很久以前，有一堆的12345671.txt2.txt3.txt......9999.txt10000.txt 摆在我面前。 我想把这些文件合并成一个叫all.txt的文件。","text":"遇到问题记得很久很久以前，有一堆的12345671.txt2.txt3.txt......9999.txt10000.txt 摆在我面前。 我想把这些文件合并成一个叫all.txt的文件。 解决办法python遇到批量问题找python！ 三下五除二，python出来了。1234567891011121314151617181920import os #获取目标文件夹的路径 meragefiledir = os.getcwd()+'\\\\MerageFiles'#获取当前文件夹中的文件名称列表 filenames=os.listdir(meragefiledir) #打开当前目录下的result.txt文件，如果没有则创建file=open('all.txt','w') #向文件中写入字符 #先遍历文件名 for filename in filenames: filepath=meragefiledir+'\\\\' filepath=filepath+filename #遍历单个文件，读取行数 for line in open(filepath): file.writelines(line) file.write('\\n') #关闭文件 file.close() 标准的读写读写。 cat命令一条命令就解决问题1cat *.txt &gt; new.txt 涨姿势了啊。cat还有这般妙用。一直以为是现实内容的。 细说cat命令原来cat 命令的名称来源于单词catenate，此单词的意思是一个接一个地连接起来。cat 命令的用途是连接文件或标准输入并打印，这个命令常用来显示文件内容，或者将 几个文件连接起来显示，或者从标准输入读取内容并显示。 基本用法12345678910cat [OPTION] [FILE]...-n 或 --number：由 1 开始对所有输出的行数编号。-b 或 --number-nonblank：和 -n 相似，只不过对于空白行不编号。-s 或 --squeeze-blank：当遇到有连续两行以上的空白行，就代换为一行的空白行。-v 或 --show-nonprinting：使用 ^ 和 M- 符号，除了 LFD 和 TAB 之外。-E 或 --show-ends : 在每行结束处显示 $。-T 或 --show-tabs: 将 TAB 字符显示为 ^I。-e : 等价于 -vE。-A, --show-all：等价于 -vET。-t：等价于&quot;-vT&quot;选项； exp1 显示文件1234# cat /etc/passwdroot:x:0:0:root:/root:/bin/bashbin:x:1:1:bin:/bin:/sbin/nologinnarad:x:500:500::/home/narad:/bin/bash exp2 显示多个文件123# cat test test1Hello everybodyHi world, exp3 使用cat命令创建文件12# cat &gt; test.txtHello everybody exp4 cat大文件时候1# cat test.txt | more exp5 显示行号1# cat -n test.txt 其他用法`bashcat -n file1 &gt; file2 把 file1 的档案内容加上行号后输入 file2 这个档案里cat -b file1 file2 &gt;&gt; file3 file1 和 file2 的文档内容加上行号（空白行不加）之后将内容附加到 file3 文档里","categories":[{"name":"linux","slug":"linux","permalink":"http://blog.fbi.st/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://blog.fbi.st/tags/linux/"}]},{"title":"docker学习笔记","slug":"docker学习笔记","date":"2019-02-01T02:17:51.000Z","updated":"2019-12-26T10:05:23.567Z","comments":true,"path":"2019/02/01/docker学习笔记/","link":"","permalink":"http://blog.fbi.st/2019/02/01/docker学习笔记/","excerpt":"1.docker是什么？？Docker 是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的Linux 机器上，也可以实现虚拟化。 容器是完全使用沙箱机制，相互之间不会有任何接口。讲简单点：docker就类似一个虚拟机软件，但是与虚拟机软件又有所区别。 docker和虚拟机的区别","text":"1.docker是什么？？Docker 是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的Linux 机器上，也可以实现虚拟化。 容器是完全使用沙箱机制，相互之间不会有任何接口。讲简单点：docker就类似一个虚拟机软件，但是与虚拟机软件又有所区别。 docker和虚拟机的区别 2.docker的重要概念镜像（image）镜像类似于虚拟机的一个快照，一般包含了系统，我们想要的服务程序等。例如：Nginx的官方image就包含了，基本的linux操作系统和Nginx服务器的程序。 容器（container）镜像（image）我们可以把它看做一个虚拟机的快照文件。这个快照 仓库（repository）docker在很多地方都借鉴了git的优秀思想，仓库这个估计也是。仓库是一个集中存放镜像的地方。这样做的好处有很多，最典型的就是，我们需要在内网多个服务器上使用某个镜像时，可以从本地的镜像仓库中pull。 注册服务器（Registry），一个注册服务器上可以有多个仓库，一个仓库里可以放多个镜像。 docker架构图 3.docker的基本操作基本操作图 常用命令 简单版 镜像（image）的操作1docker images 列出全部的image 1docker rmi [imageID,name] 删除指定的某个镜像，可以用id或者image的name。注：当有镜像正在被使用的时候是无法删除的 1docker tag [image_name:tag] [new_name:new_tag] docker给镜像（image）写标签 1docker history [imageID,name] 查看指定的镜像构成的历史 1docker run -it [imageID,name] 执行一个镜像到 容器（container）的操作1docker ps -a 查看当前的容器 1docker start","categories":[{"name":"docker","slug":"docker","permalink":"http://blog.fbi.st/categories/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.fbi.st/tags/docker/"}]},{"title":"elasticsearch_cat_api笔记","slug":"elasticsearch_cat_api笔记","date":"2018-12-09T14:57:11.000Z","updated":"2019-12-26T09:11:15.639Z","comments":true,"path":"2018/12/09/elasticsearch_cat_api笔记/","link":"","permalink":"http://blog.fbi.st/2018/12/09/elasticsearch_cat_api笔记/","excerpt":"如果经常在命令行环境下工作，cat API 对你会非常有用。用 Linux 的 cat 命令命名，这些 API 也就设计成像 *nix 命令行工具一样工作了。 他们提供的统计和前面已经讨论过的 API ( 健康、节点统计 等等 ) 是一样的。但是输出以表格的形式提供，而不是 JSON。对于系统管理员来说这是 非常 方便的，你仅仅想浏览一遍集群或者找出内存使用偏高的节点而已。","text":"如果经常在命令行环境下工作，cat API 对你会非常有用。用 Linux 的 cat 命令命名，这些 API 也就设计成像 *nix 命令行工具一样工作了。 他们提供的统计和前面已经讨论过的 API ( 健康、节点统计 等等 ) 是一样的。但是输出以表格的形式提供，而不是 JSON。对于系统管理员来说这是 非常 方便的，你仅仅想浏览一遍集群或者找出内存使用偏高的节点而已。 通过 GET 请求发送 cat 命名可以列出所有可用的 API： 123456789101112131415161718192021222324GET /_cat=^.^=/_cat/allocation/_cat/shards/_cat/shards/&#123;index&#125;/_cat/master/_cat/nodes/_cat/indices/_cat/indices/&#123;index&#125;/_cat/segments/_cat/segments/&#123;index&#125;/_cat/count/_cat/count/&#123;index&#125;/_cat/recovery/_cat/recovery/&#123;index&#125;/_cat/health/_cat/pending_tasks/_cat/aliases/_cat/aliases/&#123;alias&#125;/_cat/thread_pool/_cat/plugins/_cat/fielddata/_cat/fielddata/&#123;fields&#125; 健康（health）12345GET /_cat/health?vepoch time cluster status node.total node.data shards pri relo init1408[..] 12[..] el[..] 1 1 114 114 0 0 114unassign ?v是为了显示数据的标题 命令help我们看到集群里节点的一些统计，不过和完整的 节点统计 输出相比而言是非常基础的。你可以包含更多的指标，但是比起查阅文档，让我们直接问 cat API 有哪些可用的吧。 你可以过对任意 API 添加 ?help 参数来做到这点：1234567891011GET /_cat/nodes?helpid | id,nodeId | unique node idpid | p | process idhost | h | host nameip | i | ip addressport | po | bound transport portversion | v | es versionbuild | b | es build hash...... 节点统计（nodes）1234GET /_cat/nodes?vhost ip heap.percent ram.percent load node.role master namezacharys-air 192.168.1.131 45 72 1.85 d * Zach 1234GET /_cat/nodes?v&amp;h=ip,port,heapPercent,heapMaxip port heapPercent heapMax192.168.1.131 9300 53 990.7mb","categories":[{"name":"Elasticsearch非权威指南","slug":"Elasticsearch非权威指南","permalink":"http://blog.fbi.st/categories/Elasticsearch非权威指南/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://blog.fbi.st/tags/Elasticsearch/"}]},{"title":"MySQL触发器基本的使用","slug":"MySQL触发器基本的使用","date":"2018-11-20T02:54:24.000Z","updated":"2019-12-26T10:07:36.807Z","comments":true,"path":"2018/11/20/MySQL触发器基本的使用/","link":"","permalink":"http://blog.fbi.st/2018/11/20/MySQL触发器基本的使用/","excerpt":"触发器触发器是一种特殊的存储过程，是嵌入到mysql的一段程序，它在插入，删除或修改特定表中的数据时触发执行。 一、基本语法1. 创建触发器：12345678CREATE TRIGGER /*触发器名称*/AFTER / BEFORE /*(触发器工作的时机)*/ UPDATE / DELETE / INSERT /*(触发器监听事件)*/ ON /*表名(触发器监听的目标表)*/ FOR EACH ROW /*(行级监视，mysql固定写法，oracle不同)*/BEGIN /*sql语句集........（触发器执行动作，分号结尾）*/END;","text":"触发器触发器是一种特殊的存储过程，是嵌入到mysql的一段程序，它在插入，删除或修改特定表中的数据时触发执行。 一、基本语法1. 创建触发器：12345678CREATE TRIGGER /*触发器名称*/AFTER / BEFORE /*(触发器工作的时机)*/ UPDATE / DELETE / INSERT /*(触发器监听事件)*/ ON /*表名(触发器监听的目标表)*/ FOR EACH ROW /*(行级监视，mysql固定写法，oracle不同)*/BEGIN /*sql语句集........（触发器执行动作，分号结尾）*/END; 2. 删除触发器：1DROP TRIGGER IF exist `trigger_name`; 3. 查询数据库触发器：1SHOW triggers; 4.触发器声明变量:一个变量名可以由当前字符集的数字字母字符和“_”、“$”和“.”组成; 局部变量MySQL 中使用 DECLARE 来定义一局部变量，该变量只能在 BEGIN … END 复合语句中使用，并且应该定义在复合语句的开头，即其它语句之前。 语法是：1DECLARE var_name[...]type[DEFAULT value] 其中， var_name 为变量名称，同sql语句一样，变量名不区分大小写; type 为mysql支持的任何数据类型; DEFAULT 子句提供默认值，值可以是一个表达式 (如果需要可以使用)。 注: 可以同时定义多个同类型的变量，用逗号隔开，变量初始值为NULL； 例如：123DECLARE a INT;DECLARE b INT DEFAULT 0; 用户变量用户变量：相当与全局变量。 只在一个数据库中有效在客户端连接到数据库实例整个过程中用户变量都是有效的mysql中用户变量不需要事先声明，在用的时候直接用@变量名 使用就可以1234567/*set语句可用于向系统变量或用户变量赋值*/SET @num = 1;SET @num := 1;/*也可使用select语句来定义*/SELECT @num := 1;SELECT @num := field_name FROM table_name WHERE 1 = 1; 注：SELECT只能用:= 定义 5.变量的赋值mysql触发器内，对变量赋值采用 SET 语句语法是：1SET var_name = expr [,var_name = expr] ... 使用举例12DECLARE c INT; SET c = ( SELECT stuCount FROM class WHERE classID = new.classID ); Tips:行变量：当目标表发生改变时候，变化的行可用行变量表示new :代表目标表目标行发生改变之后的行old :代表目标表目标行发生改变之前的行 6.逻辑判断语句12345IF /*condition1*/ THEN /*do something;*/ ELSEIF /*condition2*/ THEN /*do something;*/END IF; 二、示例1.触发器监听：insert12345678910CREATE TRIGGER `trigger_name` AFTER INSERT ON `table` FOR EACH ROWBEGIN /* 要做的SQL操作，如： UPDATE table1 SET field = 'abc' WHERE id = new.id; new 是行变量。 */END; 2.触发器监听：delete12345678910CREATE TRIGGER `trigger_name2` AFTER DELETE ON `table` FOR EACH ROWBEGIN /* 要做的SQL操作，如： UPDATE table1 SET field = 'abc' WHERE id = old.id; old 是行变量。 */END; 3.触发器监听：update12345678910CREATE TRIGGER `trigger_name3` AFTER UPDATE ON `table` FOR EACH ROWBEGIN /* 要做的SQL操作，如： UPDATE table1 SET field = 'abc' WHERE id = new.id; old 是行变量。 */END; 4.触发器SET和IF语句的综合使用1234567891011121314151617CREATE TRIGGER `trigger_name4` AFTER UPDATE ON `table` FOR EACH ROWBEGIN DECLARE c INT; SET c = 1; IF c &lt; 1 THEN SET c = 2; ELSEIF c &gt; 1 THEN SET c = 4; END IF; /* 要做的SQL操作，如： UPDATE table1 SET field = 'abc' WHERE id = new.id; old 是行变量。 */END; 注意：①：for each row:必须填写，保证mysql支持行级控制，oracle同时支持行级控制和语句级控制。②：如果在BEFORE或AFTER触发程序的执行过程中出现错误，将导致调用触发程序的整个语句的失败。对于事务性表，如果触发程序失败（以及由此导致的整个语句的失败），该语句所执行的所有更改将回滚。对于非事务性表，不能执行这类回滚，因而，即使语句失败，失败之前所作的任何更改依然有效。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://blog.fbi.st/categories/数据库/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.fbi.st/tags/MySQL/"}]},{"title":"虚拟机装osx","slug":"虚拟机装osx","date":"2018-11-10T07:06:34.000Z","updated":"2019-12-26T09:56:36.719Z","comments":true,"path":"2018/11/10/虚拟机装osx/","link":"","permalink":"http://blog.fbi.st/2018/11/10/虚拟机装osx/","excerpt":"准备工作工具/原料VMware® Workstation 12 Prounlocker 208（for OS X 插件补丁）Mac OS X 10.11镜像darwin.iso 方法/步骤1. 下载以上文件2. unlocker208安装","text":"准备工作工具/原料VMware® Workstation 12 Prounlocker 208（for OS X 插件补丁）Mac OS X 10.11镜像darwin.iso 方法/步骤1. 下载以上文件2. unlocker208安装 VM安装完成后，打开任务管理器，找到服务项，选择按描述排序，将框中关于VMware全部停止运行。 解压unlocker208文件，找到win-install.cmd文件，右键以管理员身份运行 。 这一步骤很关键，决定了后续VM会不会识别出OS X。 我安装的时候，出现了VM无法识别Mac OS X 的问题，找到了好多 unlocker文件都没能解决，最后试了下208可以了。 3. 创建虚拟机4. 选择安装程序光盘映像文件，点击选择CDR镜像文件路径 5. 选择安装Apple Mac OS X 如果第二步unlocker文件没有处理好的话，这个地方可能就不会出现Apple Mac OS X。如果不行，可以多下载几个unlocker试试。版本根据实际版本选择，我的是10.11.如果还是不行，关闭所有的vm进程和服务后再试试（我就是这样试好的） 6. 名称和安装位置自己定义一下7. 指定磁盘大小 40G ，我选择的是“将虚拟磁盘拆分成多个文件”,点击”下一步”8. 自定义硬件 设置内存4G CPU 4个 点击“完成”点击编辑虚拟机设置–》点击选项卡–》常规中 “增强型键盘”选择“在可用时使用（推荐）” 不设置,后面是没办法使用键盘操作的 开启虚拟机会提出错误 解决上面错误方法：找到VM安装的根文件，找到根文件下的 OS X xx.xx.vmx，右键用记事本方式打开，找到smc.present = &quot;TRUE&quot;在其后面加上smc.version = &quot;0&quot; 保存关闭，再开启时就没有错误了。 如果开启出现如下图蓝屏项有两种可能： CD/DVD(IDE)设置问题 看看设备状态的“启动时连接”是否勾选； 你下载的镜像文件有问题; 如果开启出现苹果标后重启现象，基本确定是您的电脑的硬件DEP（数据执行保护）打开了。 关闭操作： 硬件DEP选项一般都会包含&quot;EXECUTE DISABLE BIT&quot;, &quot;NX&quot;, &quot;DATA EXECUTION PREVENTION&quot; 或 &quot;XD&quot; 四个关键词中的一个。一般都能在主菜单的“Power”或“Advanced”中找到，设置为Disabled后重新启动电脑(最好是冷启动)即可。这下启动虚拟机一切正常了选择系统语言 继续选择“磁盘工具”选择虚拟磁盘 点击 抹掉选择 硬盘安装恭喜你，已经成功了，等待安装完成","categories":[{"name":"tools","slug":"tools","permalink":"http://blog.fbi.st/categories/tools/"}],"tags":[{"name":"tools","slug":"tools","permalink":"http://blog.fbi.st/tags/tools/"}]},{"title":"看完《我不是药神》后我用python分析了武汉的药店","slug":"看完《我不是药神》后我用python分析了中国的药店","date":"2018-10-20T12:13:31.000Z","updated":"2019-12-26T09:56:01.783Z","comments":true,"path":"2018/10/20/看完《我不是药神》后我用python分析了中国的药店/","link":"","permalink":"http://blog.fbi.st/2018/10/20/看完《我不是药神》后我用python分析了中国的药店/","excerpt":"起因其实打算分析药店这个事情，与看完《我不是药神》没啥关系，取这个标题，只是为了蹭一波电影的热度。主要起因是，在世界杯期间看到一条段子： 美国500米就有一个篮球场，巴西每个小区一个足球场，而中国500米就有个大药房。 开始只是当成一个段子，觉得有夸张的嫌疑。但某天逛完超市回家，刻意的数了一下药店数量。 震惊! 不到1km的路上居然有6，7个药店！真可怕。 正好我最近刚开始学习python数据分析，于是，就决心以“超一线城市大武汉”为例，好好看看中国的药店到底多不多。","text":"起因其实打算分析药店这个事情，与看完《我不是药神》没啥关系，取这个标题，只是为了蹭一波电影的热度。主要起因是，在世界杯期间看到一条段子： 美国500米就有一个篮球场，巴西每个小区一个足球场，而中国500米就有个大药房。 开始只是当成一个段子，觉得有夸张的嫌疑。但某天逛完超市回家，刻意的数了一下药店数量。 震惊! 不到1km的路上居然有6，7个药店！真可怕。 正好我最近刚开始学习python数据分析，于是，就决心以“超一线城市大武汉”为例，好好看看中国的药店到底多不多。 数据获取通过地图WebAPI我尝试着找了一下，好像网上没有现成的数据。只能自己动手，搞点数据了。 首先想到的是通过百度地图来获取数据，找了找，果然有相关的WebAPI。 地点检索服务（又名Place API）是一类Web API接口服务；服务提供多种场景的地点（POI）检索功能，包括城市检索、圆形区域检索、矩形区域检索。开发者可通过接口获取地点（POI）基础或详细地理信息。 能直接通过WebAPI获取数据，连解析页面都省了，简直太爽了有木有？ 本以为可以直接通过城市的检索的接口直接获取到我想要的数据。然鹅，我错了，事情没我想的那么简单，这个api居然最多返回400条数据。大武汉的药店明显不止400个。我试着找了一下高德，高德更抠门，就200个结果。只能想想其他办法了。 切割地图继续找其他的解决办法，忽然发现了地点检索api后面还有一个矩形区域检索功能。灵机一动，我可以把大武汉分成很多个小矩形，分块检索啊，这样也不会有数据丢失。 想法很好，可当我看到武汉这长得像块‘三鲜豆皮’的地图的时候，问题又来了，我该怎么切割这个地图。 抱着不能错过一个，也不能浪费api资源的态度，我打算先找到武汉东南西北之最，也就是找到一个可以将武汉包裹的最小矩形。 想到了通过城市边界点筛选的方式获取武汉的最东，最南，最西，最北。结果找了半天没发现百度webapi里有这个，只有一个javascriptAPI有这个功能，比较麻烦。反倒是高德有个“行政区域查询”的api可以直接获取到城市边界。1http://restapi.amap.com/v3/config/district?key=您的key&amp;keywords=武汉&amp;subdistrict=0&amp;extensions=all 接下来的事情就简单了，分析获取到的城市边界点列表，找到经纬度的最大最小值，即城市的最东南西北。然后从东到西切20刀，从南到北均匀切20刀。武汉一下就被切成400块了。 我们就可以分块的去调用地点检索的API，如果有超过400个的，就调整参数，多切几刀。 当然，这样切肯定有误伤周边城市的情况。这种情况就通过POI的“city”属性去筛选掉。 至此，我们就成功的获取到了我们想要的比较完整的药店的数据了。 其他数据有了药店的数据，我们还需要一些其他的数据，例如：行政区域面积啊，人口数量等。像这类的数据，一般在当地的统计局网站都能下载到。 数据分析药店位置分布我猜想，药店的数量应该与人口密度和地方经济情况有所关系。 首先，我们通过图表看看武汉的人口密度： 从图像可以看出，人口密度最大的是江汉区，硚口区和武昌区，这些都是武汉的老城区。黄陂区，江夏，汉南这些都算是郊区，人口密度低，也情有可原。意外的是：主城区洪山区人口密度居然也不高。（可能统计面积的时候几个大湖也算进去了？） 再看看，我们收集的药店的数据，我爬取的百度地图上能找到的武汉所有药店，一共爬到了1936个，估计还有一些没有收录到的遗漏了。在武汉药监局官网查到的药品零售企业有4317个，但这里可能又很多过期可但未注销的企业。所以这次我们以百度地图爬取到的数据为准。 首先我们看看各个区人数和药店数量的基本情况： 基本大多数的区药店数量都超过了1万人一个药店。 再看看武汉每个区的药店数量情况，武汉各个区域药店的数量占比： 武昌、江岸、洪山、江汉这几个主城区果然还是占了大多的数的药店。 药店密度和人口密度是否有关呢？ 药店最密集的是江岸区，3408个人就有一个药店。而药店比较稀缺的新洲区居然平均26317个人才有一个药店，新洲区的朋友会不会有买药难的问题？ 经济状况好的主城区人均药店数明显比郊区高。 光在表格上我们没办法形象的看到药店的分布，所以做成热力图更形象了。 药店店名分析","categories":[{"name":"python","slug":"python","permalink":"http://blog.fbi.st/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://blog.fbi.st/tags/python/"}]},{"title":"SQLAlchemy的属性介绍","slug":"SQLAlchemy的属性介绍","date":"2018-09-26T13:20:54.000Z","updated":"2019-12-26T10:09:30.302Z","comments":true,"path":"2018/09/26/SQLAlchemy的属性介绍/","link":"","permalink":"http://blog.fbi.st/2018/09/26/SQLAlchemy的属性介绍/","excerpt":"SQLAlchemy的应用行数据类型 类型 说明 Integer 整数 String (size) 有最大长度的字符串 Text 长 unicode 文本 Date 表示为日期 DateTime 表示为 datetime 对象 的时间和日期 Float 存储浮点值 Boolean 存储布尔值 PickleType 存储一个持久化 Python 对象 LargeBinary 存储任意大的二进制数据","text":"SQLAlchemy的应用行数据类型 类型 说明 Integer 整数 String (size) 有最大长度的字符串 Text 长 unicode 文本 Date 表示为日期 DateTime 表示为 datetime 对象 的时间和日期 Float 存储浮点值 Boolean 存储布尔值 PickleType 存储一个持久化 Python 对象 LargeBinary 存储任意大的二进制数据 其他行属性primary_key=True 是否是主键db.ForeignKey(&#39;person.id&#39;) 表示设置XX表名.XX字段名外键nullable=False 是否能为空unique=True 是否能重复autoincrement=True 是否自增长default=0 默认值index=True 索引name 名称type_ 列类型 关系链接一对多的关系： 如果要表示一对一的关系，在定义relationship 的时候设置uselist 为False （默认为True ） db.relationship(&#39;Teams&#39;) 定义一个关系backref=db.backref(&#39;users&#39;) 反向引用primaryjoin=&#39;Persion.like_id==Book.id&#39; 多个外键的情况 多对多的关系有中间表： secondary = 中间表模型, 123456789101112tags = db.Table(&apos;tags&apos;, db.Column(&apos;tag_id&apos;, db.Integer, db.ForeignKey(&apos;tag.id&apos;)), db.Column(&apos;page_id&apos;, db.Integer, db.ForeignKey(&apos;page.id&apos;)))class Page(db.Model): id = db.Column(db.Integer, primary_key=True) tags = db.relationship(&apos;Tag&apos;, secondary=tags, backref=db.backref(&apos;pages&apos;, lazy=&apos;dynamic&apos;))class Tag(db.Model): id = db.Column(db.Integer, primary_key=True) secondary=association_table, back_populates=&quot;children&quot; 循环一对多关系还是我自己写的Persion和Book关系，一个人可能写过多本书，一本Book只有一个Persion写，N个人最喜欢1个书，每个人只能有一个最喜欢的这个例子可能不大恰当，但是就是两个单向的一对多关系，是不能用多对多关系的，下面是我给出的例子1234567891011121314class Persion(Base): __tablename__ = 'persion' id = Column(Integer, autoincrement=True, primary_key=True) name = Column(String(1024)) like_id = Column(Integer, ForeignKey('book.id')) books = relationship('Book', backref='auther', lazy=\"dynamic\", primaryjoin='Book.auther_id==Persion.id')class Book(Base): __tablename__ = 'book' id = Column(Integer, autoincrement=True, primary_key=True) likes = relationship('Persion', backref='like', lazy=\"dynamic\", primaryjoin='Persion.like_id==Book.id') name = Column(String(1024)) auther_id = Column(Integer, ForeignKey('persion.id')) 主要是添加primaryjoin 属性，说明关联的字段在使用sqlalchemy的时候有很多属性，类似lazy ，backref ，primaryjoin 这样的属性，备选项很多，需要多多查询官方文档。只有使用过过才会比较熟悉 表的引擎和编码123456789101112131415161718Table('mytable', metadata, Column('data', String(32)), mysql_engine='InnoDB', mysql_charset='utf8', mysql_key_block_size=\"1024\" )``` 或```pyclass User(Base): \"\"\"Users table\"\"\" # 表的名字 __tablename__='users' __table_args__=&#123;'sqlite_autoincrement': True,'mysql_engine': 'InnoDB','mysql_charset': 'utf8'&#125; # 表结构 id=Column(Integer,primary_key=True,autoincrement=True)","categories":[{"name":"python","slug":"python","permalink":"http://blog.fbi.st/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://blog.fbi.st/tags/python/"}]},{"title":"SQLAlchemy的基本操作","slug":"SQLAlchemy的基本操作","date":"2018-09-23T11:57:17.000Z","updated":"2019-12-26T10:09:15.343Z","comments":true,"path":"2018/09/23/SQLAlchemy的基本操作/","link":"","permalink":"http://blog.fbi.st/2018/09/23/SQLAlchemy的基本操作/","excerpt":"安装通过pip安装SQLAlchemy 1$ pip install sqlalchemy","text":"安装通过pip安装SQLAlchemy 1$ pip install sqlalchemy 连接数据库Flask config配置方法以MySQL为例1234567891011#config.pyDB_URI = \"mysql://&#123;&#125;:&#123;&#125;@&#123;&#125;:&#123;&#125;/&#123;&#125;?charset=utf8\".format(USERNAME,PASSWORD,HOST_NAME,PROT,DATABAES)SQLALCHEMY_DATABASE_URI =DB_URI#models.pyfrom flask import Flaskfrom flask_sqlalchemy import SQLAlchemydb = SQLAlchemy()app = Flask(__name__)app.config.from_object(config)db.init_app(app) 直接连接的写法1234567891011121314151617# coding:utf-8from sqlalchemy import create_enginefrom sqlalchemy.orm import sessionmaker#sqlite内存：DATABAES_URL = 'sqlite:///:memory:'#sqlite文件: DATABAES_URL = 'sqlite:///./test.db'#mysql+pymysql：DATABAES_URL = 'mysql+pymysql://username:password@hostname:port/dbname'#mssql+pymssql: DATABAES_URL ='mssql+pymssql://username:password@hostname:port/dbname'engine = create_engine(DATABAES_URL,echo=True)DB_Session = sessionmaker(bind=engine)#create_engine() 会返回一个数据库引擎，echo 参数为 True 时，会显示每条执行的 SQL 语句，生产环境下可关闭。session = DB_Session() 创建数据模型12345678910111213141516171819from flask import Flaskfrom flask_sqlalchemy import SQLAlchemy,Columnapp = Flask(__name__)db = SQLAlchemy(app)# 定义Person对象class Person(db.Model): '''Person table''' # 表的名字 __tablename__ = \"person\" __table_args__ = &#123; \"mysql_engine\":\"InnoDB\", # 表的引擎 \"mysql_charset\":\"utf8\" # 表的编码格式 &#125; # 表结构 id=Column(Integer,primary_key=True,autoincrement=True) name = Column(String(128),primary_key=True,nullable=False)db.create_all() * 表结构更具体的参数设置,如主键、自增、外键等属性，见另一篇文章 [ SQLAlchemy的应用 ] 数据的CRUD 添加数据 12345person = Person(name = 'aaa')db.session.add(person)#事务提交db.session.commit()db.session.close() 查询数据 12person = Person.query.filter(Person.name = 'aaa').first()print person.name 修改数据 12345# 先把要修改的数据查找出来person = Person.query.filter(Person.name = 'aaa').first()person.name = 'bbb'db.session.commit()db.session.close() 删除数据 12345# 先把要修改的数据查找出来person = Person.query.filter(Person.name = 'aaa').first()db.session.delete(person)db.session.commit()db.session.close() 增、删、改操作都需要提交事务db.session.commit() ,查询操作不需要 执行sql语句使用execute() 方法123456789101112131415s=db.session()# 不能用 `?` 的方式来传递参数 要用 `:param` 的形式来指定参数# s.execute('INSERT INTO person (name, age, password) VALUES (?, ?, ?)',('bigpang',2,'1122121')) # 这样执行报错 # s.execute('INSERT INTO person (name, age, password) VALUES (:aa, :bb, :cc)',(&#123;'aa':'bigpang2','bb':22,'cc':'998'&#125;))# s.commit()# 这样执行成功res=s.execute('select * from person where name=:aaa',&#123;'aaa':'aaa'&#125;)# print(res['name']) # 错误# print(res.name) # 错误# print(type(res)) # 错误for r in res: print(r['name']) s.close() 完整的示例代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180# coding:utf-8from sqlalchemy import create_enginefrom sqlalchemy.ext.declarative import declarative_basefrom sqlalchemy import Column, Integer, Stringfrom sqlalchemy.orm import sessionmaker# ***************************# 初始化数据库连接DATABAES_URL = 'mysql+pymysql://username:password@hostname:port/dbname'engine = create_engine(DATABAES_URL,echo=True)# 创建对象的基类Base=declarative_base()# 创建会话类DBSession=sessionmaker(bind=engine)# ******************# 定义User对象class User(Base): \"\"\"Users table\"\"\" # 表的名字 __tablename__='users' __table_args__=&#123;'sqlite_autoincrement': True&#125; # 表结构 id=Column(Integer,primary_key=True,autoincrement=True) name=Column(String(32),nullable=False) age=Column(Integer,default=0) password=Column(String(64),unique=True)class Blog(Base): \"\"\"docstring for Blog\"\"\" __tablename__='blogs' id=Column(Integer,primary_key=True) title=Column(String(100)) desc=Column(String(500))class Tips(Base): \"\"\"docstring for Tips\"\"\" __tablename__='tips' #表结构 id=Column(Integer,primary_key=True) name=Column(String(32))# ***********************# 添加一条数据def newUser(): # 创建会话对象 session=DBSession() new_user=User(name='Jery',password='123') session.add(new_user) session.commit() session.close()# 添加一条数据def addUserForZhCn(): session=DBSession() new_user=User(name=u'关羽2',password='12322233') session.add(new_user) session.commit() session.close()# 新增多条数据def addmoreUser(): session=DBSession() session.add_all([ User(name='guanyu',age=4,password='11111'), User(name='zhangfei',password='2233'), User(name='zhenji',password='44556') ]) session.commit() session.close()# 查询def queryUser(): session=DBSession() quser=session.query(User).filter(User.id==4).one() print('name:',quser.name) session.close()# 删除def deleteUser(): session=DBSession() duser=session.query(User).filter(User.id==2).delete() session.commit() session.close()# 执行sql语句def SQlUser(): s=DBSession() # 不能用 `?` 的方式来传递参数 要用 `:param` 的形式来指定参数 # s.execute('INSERT INTO users (name, age, password) VALUES (?, ?, ?)',('bigpang',2,'1122121')) # 这样执行报错 # s.execute('INSERT INTO users (name, age, password) VALUES (:aa, :bb, :cc)',(&#123;'aa':'bigpang2','bb':22,'cc':'998'&#125;)) # s.commit() # 这样执行成功 res=s.execute('select * from users where age=:aaa',&#123;'aaa':4&#125;) # print(res['name']) # 错误 # print(res.name) # 错误 # print(type(res)) # 错误 for r in res: print(r['name']) s.close()# 执行sql语句def SQlUser2(): # **传统 connection方式** # 创建一个connection对象，使用方法与调用python自带的sqlite使用方式类似 # 使用with 来创建 conn，不需要显示执行关闭连接 # with engine.connect() as conn: # res=conn.execute('select * from users') # data=res.fetchone() # print('user is %s' %data[1]) # 与python自带的sqlite不同，这里不需要 cursor 光标，执行sql语句不需要commit。如果是增删改，则直接生效，也不需要commit. # **传统 connection 事务** with engine.connect() as conn: trans=conn.begin() try: r1=conn.execute(\"select * from users\") print(r1.fetchone()[1]) r2=conn.execute(\"insert into users (name,age,password) values (?,?,?)\",('tang',5,'133444')) trans.commit() except: trans.rollback() raise # **session** session=DBSession() session.execute('select * from users') session.execute('insert into users (name,age,password) values (:name,:age,:password)',&#123;\"name\":'dayuzhishui','age':6,'password':'887'&#125;) # 注意参数使用dict，并在sql语句中使用:key占位 # 如果是增删改，需要 commit session.commit() # 用完记得关闭，也可以用 with session.close()# 更多操作def TestUser(): session=DBSession() # test1 # 使用merge方法，如果存在则修改，如果不存在则插入（只判断主键，不判断unique列） # t1=session.query(User).filter(User.name=='zhenji').first() # t1.age=34 # session.merge(t1) # session.commit() # test2 # merge方法，如果数据库中没有则添加 # t2=User() # t2.name='haha' # session.merge(t2) # session.commit() # test3 # 获取第2-3项 # tUser=session.query(User)[1:3] # for u in tUser: # print(u.id) # test4 # if __name__ == '__main__': # 删除全部数据库 # Base.metadata.drop_all(engine) # 初始化数据库 # Base.metadata.create_all(engine) # 删除全部数据库 # Base.metadata.drop_all(engine) # 删除指定的数据库 # 如删除 Blogs表 # 详见 ：http://stackoverflow.com/questions/35918605/how-to-delete-a-table-in-sqlalchemy # Blog.__table__.drop(engine) # 新增数据 # newUser() # 新增多条数据 # addmoreUser() # 新增数据含中文 # addUserForZhCn() # 查询数据 # queryUser() # 删除 # deleteUser() # 测试 # TestUser() # 执行sql语句 # SQlUser() # 执行sql语句2 SQlUser2() print('ok')","categories":[{"name":"python","slug":"python","permalink":"http://blog.fbi.st/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://blog.fbi.st/tags/python/"}]},{"title":"Redis非权威指南(基本知识)","slug":"redis非权威指南(基本知识)","date":"2018-08-20T12:07:31.000Z","updated":"2019-12-26T10:08:58.955Z","comments":true,"path":"2018/08/20/redis非权威指南(基本知识)/","link":"","permalink":"http://blog.fbi.st/2018/08/20/redis非权威指南(基本知识)/","excerpt":"Redis 简介Redis是完全开源免费的一个高性能的key-value存储系统。它可以用作数据库、缓存和消息中间件。 Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用。 Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。 Redis支持数据的备份，即master-slave模式的数据备份。","text":"Redis 简介Redis是完全开源免费的一个高性能的key-value存储系统。它可以用作数据库、缓存和消息中间件。 Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用。 Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。 Redis支持数据的备份，即master-slave模式的数据备份。 Redis的特点Redis将其数据库完全保存在内存中，因此性能极高,能读的速度是110000次/s,写的速度是81000次/s 。Redis支持开发人员常用的大多数数据类型，例如列表，集合，排序集和散列等等。这使得Redis很容易被用来解决各种问题，因为我们知道哪些问题可以更好使用地哪些数据类型来处理解决。Redis的所有操作都是原子性的，同时Redis还支持对几个操作全并后的原子性执行。Redis还支持 publish/subscribe, 通知, key 过期等等特性。 Redis在项目中的作用Redis在项目中使用一般作为主要缓存服务。 1、会话缓存（Session Cache）最常用的一种使用Redis的情景是会话缓存（session cache）。用Redis缓存会话比其他存储（如Memcached）的优势在于：Redis提供持久化。 随着 Redis 这些年的改进，很容易找到怎么恰当的使用Redis来缓存会话的文档。甚至广为人知的商业平台Magento也提供Redis的插件。 2、全页缓存（FPC）除基本的会话token之外，Redis还提供很简便的FPC平台。回到一致性问题，即使重启了Redis实例，因为有磁盘的持久化，用户也不会看到页面加载速度的下降，这是一个极大改进，类似PHP本地FPC。 再次以Magento为例，Magento提供一个插件来使用Redis作为全页缓存后端。 此外，对WordPress的用户来说，Pantheon有一个非常好的插件 wp-redis，这个插件能帮助你以最快速度加载你曾浏览过的页面。 3、队列Reids在内存存储引擎领域的一大优点是提供 list 和 set 操作，这使得Redis能作为一个很好的消息队列平台来使用。Redis作为队列使用的操作，就类似于本地程序语言（如Python）对 list 的 push/pop 操作。 如果你快速的在Google中搜索“Redis queues”，你马上就能找到大量的开源项目，这些项目的目的就是利用Redis创建非常好的后端工具，以满足各种队列需求。例如，Celery有一个后台就是使用Redis作为broker，你可以从这里去查看。 4、排行榜/计数器Redis在内存中对数字进行递增或递减的操作实现的非常好。集合（Set）和有序集合（Sorted Set）也使得我们在执行这些操作的时候变的非常简单，Redis只是正好提供了这两种数据结构。 5、发布/订阅发布/订阅的使用场景确实非常多。人们在社交网络连接中使用，还可作为基于发布/订阅的脚本触发器，甚至用Redis的发布/订阅功能来建立聊天系统！ Redis 对比 memcached 对比 持久化 数据一致性 数据类型 redis 支持持久化 无cas命令/有事务 多种数据结构 memcached 不支持持久化 有cas保证数据一致性 单一key-value结构 Redis安装Window 下安装下载地址：https://github.com/MSOpenTech/redis/releases Redis 支持 32 位和 64 位。这个需要根据你系统平台的实际情况选择，这里我们下载 Redis-x64-xxx.zip压缩包到 C 盘，解压后，将文件夹重新命名为 redis。 打开一个 cmd 窗口 使用cd命令切换目录到 C:\\redis 运行 :1redis-server.exe redis.windows.conf 如果想方便的话，可以把 redis 的路径加到系统的环境变量里，这样就省得再输路径了，后面的那个 redis.windows.conf 可以省略，如果省略，会启用默认的。输入之后，会显示如下界面： 这时候另启一个cmd窗口，原来的不要关闭，不然就无法访问服务端了。切换到redis目录下运行1redis-cli.exe -h 127.0.0.1 -p 6379 设置键值对: set myKey abc取出键值对: get myKey Linux下安装下载地址：http://redis.io/download，下载最新文档版本。本教程使用的最新文档版本为 2.8.17，下载并安装：1234$ wget http://download.redis.io/releases/redis-2.8.17.tar.gz$ tar xzf redis-2.8.17.tar.gz$ cd redis-2.8.17$ make make完后 redis-2.8.17目录下会出现编译后的redis服务程序redis-server, 还有用于测试的客户端程序redis-cli,两个程序位于安装目录 src 目录下：下面启动redis服务. 12$ cd src$ ./redis-server 注意这种方式启动redis 使用的是默认配置。也可以通过启动参数告诉redis使用指定配置文件使用下面命令启动。 12$ cd src$ ./redis-server redis.conf redis.conf是一个默认的配置文件。我们可以根据需要使用自己的配置文件。启动redis服务进程后，就可以使用测试客户端程序redis-cli和redis服务交互了。 比如: 123456$ cd src$ ./redis-cliredis&gt; set foo barOKredis&gt; get foo&quot;bar&quot; Ubuntu 下安装在 Ubuntu 系统安装 Redi 可以使用以下命令: 12$sudo apt-get update$sudo apt-get install redis-server 启动 Redis 1$ redis-server 查看 redis 是否启动？ 1$ redis-cli 以上命令将打开以下终端： 1redis 127.0.0.1:6379&gt; 127.0.0.1 是本机 IP ，6379 是 redis 服务端口。现在我们输入 PING 命令。 12redis 127.0.0.1:6379&gt; pingPONG 以上说明我们已经成功安装了redis。 Redis 配置Redis 的配置文件位于 Redis 安装目录下，文件名为 redis.conf。你可以通过 CONFIG 命令查看或设置配置项。 1.查看配置(GET命令)Redis CONFIG 命令格式如下： 1redis 127.0.0.1:6379&gt; CONFIG GET CONFIG_SETTING_NAME 例如1redis 127.0.0.1:6379&gt; CONFIG GET loglevel 1) “loglevel”2) “notice” 2.配置redis(SET命令)CONFIG SET 命令基本语法： 1redis 127.0.0.1:6379&gt; CONFIG SET CONFIG_SETTING_NAME NEW_CONFIG_VALUE 例如123456redis 127.0.0.1:6379&gt; CONFIG SET loglevel &quot;notice&quot; OK redis 127.0.0.1:6379&gt; CONFIG GET loglevel 1) &quot;loglevel&quot;2) &quot;notice&quot; 3.redis配置文件详解查看链接：redis 配置 参数 详解 Redis 数据类型Redis支持五种数据类型：string（字符串），hash（哈希），list（列表），set（集合）及zset(sorted set：有序集合)。 String（字符串）string是redis最基本的类型，你可以理解成与Memcached一模一样的类型，一个key对应一个value。string类型是二进制安全的。意思是redis的string可以包含任何数据。比如jpg图片或者序列化的对象 。string类型是Redis最基本的数据类型，一个键最大能存储512MB。 例如 1234redis 127.0.0.1:6379&gt; SET name &quot;hello&quot;OKredis 127.0.0.1:6379&gt; GET name&quot;hello&quot; 在以上实例中我们使用了 Redis 的 SET 和 GET 命令。键为 name，对应的值为 hello。 注意：一个键最大能存储512MB。 Hash（哈希）Redis hash 是一个键名对集合。Redis hash是一个string类型的field和value的映射表，hash特别适合用于存储对象。 例如 123456789127.0.0.1:6379&gt; HMSET user:1 username hello password hello points 200OK127.0.0.1:6379&gt; HGETALL user:11) &quot;username&quot;2) &quot;hello&quot;3) &quot;password&quot;4) &quot;hello&quot;5) &quot;points&quot;6) &quot;200&quot; 以上实例中 hash 数据类型存储了包含用户脚本信息的用户对象。 实例中我们使用了 Redis HMSET, HGETALL命令，user:1 为键值。每个 hash 可以存储 232 -1 键值对（40多亿）。 List（列表）Redis表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边）。 例如：1234567891011redis 127.0.0.1:6379&gt; lpush hello redis(integer) 1redis 127.0.0.1:6379&gt; lpush hello mongodb(integer) 2redis 127.0.0.1:6379&gt; lpush hello rabitmq(integer) 3redis 127.0.0.1:6379&gt; lrange hello 0 101) &quot;rabitmq&quot;2) &quot;mongodb&quot;3) &quot;redis&quot;redis 127.0.0.1:6379&gt; 列表最多可存储 2^32 - 1 元素 (4294967295, 每个列表可存储40多亿)。 Set（集合）Redis的Set是string类型的无序集合。集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)。 sadd命令 添加一个string元素到,key对应的set集合中，成功返回1,如果元素已经在集合中返回0,key对应的set不存在返回错误。 1sadd key member 例如： 12345678910111213redis 127.0.0.1:6379&gt; sadd hello redis(integer) 1redis 127.0.0.1:6379&gt; sadd hello mongodb(integer) 1redis 127.0.0.1:6379&gt; sadd hello rabitmq(integer) 1redis 127.0.0.1:6379&gt; sadd hello rabitmq(integer) 0redis 127.0.0.1:6379&gt; smembers hello1) &quot;rabitmq&quot;2) &quot;mongodb&quot;3) &quot;redis&quot; 注意：以上实例中 rabitmq 添加了两次，但根据集合内元素的唯一性，第二次插入的元素将被忽略。集合中最大的成员数为 232 - 1(4294967295, 每个集合可存储40多亿个成员)。 zset(sorted set：有序集合)Redis zset 和 set 一样也是string类型元素的集合,且不允许重复的成员。不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。 zset的成员是唯一的,但分数(score)却可以重复。 zadd 命令添加元素到集合，元素在集合中存在则更新对应scorezadd key score member 例如12345678910111213redis 127.0.0.1:6379&gt; zadd hello 0 redis(integer) 1redis 127.0.0.1:6379&gt; zadd hello 0 mongodb(integer) 1redis 127.0.0.1:6379&gt; zadd hello 0 rabitmq(integer) 1redis 127.0.0.1:6379&gt; zadd hello 0 rabitmq(integer) 0redis 127.0.0.1:6379&gt; ZRANGEBYSCORE hello 0 10001) &quot;redis&quot;2) &quot;mongodb&quot;3) &quot;rabitmq&quot;","categories":[{"name":"数据库","slug":"数据库","permalink":"http://blog.fbi.st/categories/数据库/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://blog.fbi.st/tags/数据库/"},{"name":"Redis","slug":"Redis","permalink":"http://blog.fbi.st/tags/Redis/"}]},{"title":"基本的shell操作HBase","slug":"基本的shell操作HBase","date":"2018-05-20T14:13:01.000Z","updated":"2019-12-26T09:55:24.943Z","comments":true,"path":"2018/05/20/基本的shell操作HBase/","link":"","permalink":"http://blog.fbi.st/2018/05/20/基本的shell操作HBase/","excerpt":"","text":"1.进入hbase shell console shell```12&gt; 如果有kerberos认证，需要事先使用相应的keytab进行一下认证（使用kinit命令），&gt; 认证成功之后再使用hbase shell进入可以使用``whoami``命令可查看当前用户 hbase(main) &gt; whoami12345678&lt;!--more--&gt;## **2表的管理**&gt; 1）查看有哪些表hbase(main)&gt; list&gt; 2）创建表*语法*：```create &lt;table&gt;, &#123;NAME =&gt; &lt;family&gt;, VERSIONS =&gt; &lt;VERSIONS&gt;&#125; 例如：创建表t1，有两个family name：f1，f2，且版本数均为2123hbase(main)&gt; create &apos;t1&apos;,&#123;NAME =&gt;&apos;f1&apos;, VERSIONS =&gt; 2&#125;,&#123;NAME =&gt;&apos;f2&apos; , VERSIONS =&gt; 2&#125; 3）删除表分两步：首先disable，然后drop例如：删除表t112hbase(main)&gt; disable &apos;t1&apos;hbase(main)&gt; drop &apos;t1&apos; 4）查看表的结构语法：describe &lt;table&gt;例如：查看表t1的结构1hbase(main)&gt; describe &apos;t1&apos; 5）修改表结构修改表结构必须先disable语法：alter &#39;t1&#39;, {NAME =&gt; &#39;f1&#39;}, {NAME =&gt; &#39;f2&#39;, METHOD =&gt; &#39;delete&#39;}例如：修改表test1的cf的TTL为180天12345hbase(main)&gt; disable &apos;test1&apos;hbase(main)&gt; alter &apos;test1&apos;,&#123;NAME=&gt;&apos;body&apos; ,TTL=&gt;&apos;15552000&apos;&#125;,&#123;NAME=&gt;&apos;meta&apos;, TTL=&gt;&apos;15552000&apos;&#125;hbase(main)&gt;enable &apos;test1&apos; 3.权限管理 1）分配权限# 语法 : grant 参数后面用逗号分隔权限用五个字母表示： “RWXCA”.WRITE('W'), EXEC('X'), CREATE('C'), ADMIN('A')```12例如，给用户‘test&apos;分配对表t1有读写的权限，```hbase(main)&gt; grant &apos;test&apos; , &apos;RW&apos; , &apos;t1&apos; 2）查看权限语法：user_permission &lt;table&gt;例如，查看表t1的权限列表user_permission 't1'```123&gt; 3）收回权限与分配权限类似,*语法*：```revoke &lt;user&gt; &lt;table&gt; &lt;column family&gt; &lt;column qualifier&gt; 例如，收回test用户在表t1上的权限1hbase(main)&gt; revoke &apos;test&apos; , &apos;t1&apos; 4.表数据的增删改查 1）添加数据语法：put &lt;table&gt;,&lt;rowkey&gt;,&lt;family:column&gt;,&lt;value&gt;,&lt;timestamp&gt;例如：给表t1的添加一行记录：rowkey是rowkey001，family name：f1，column name：col1，value：value01，timestamp：系统默认123hbase(main)&gt; put &apos;t1&apos; , &apos;rowkey001&apos; , &apos;f1:col1&apos;, &apos;value01&apos; 用法比较单一。 2）查询数据a）查询某行记录语法：get &lt;table&gt;,&lt;rowkey&gt;,[&lt;family:column&gt;,....]例如：查询表t1，rowkey001中的f1下的col1的值12hbase(main)&gt; get &apos;t1&apos;,&apos;rowkey001&apos; , &apos;f1:col1&apos; 或者：12hbase(main)&gt; get &apos;t1&apos; , &apos;rowkey001&apos; ,&#123;COLUMN=&gt;&apos;f1:col1&apos;&#125; 查询表t1，rowke002中的f1下的所有列值1hbase(main)&gt; get &apos;t1&apos;,&apos;rowkey001&apos; b）扫描表语法：scan &lt;table&gt;, {COLUMNS =&gt; [ &lt;family:column&gt;,.... ], LIMIT =&gt; num}另外，还可以添加STARTROW、TIMERANGE和FITLER等高级功能例如：扫描表t1的前5条数据1hbase(main)&gt; scan &apos;t1&apos; , &#123;LIMIT=&gt;5&#125; c）查询表中的数据行数语法：, &#123;INTERVAL 12INTERVAL设置多少行显示一次及对应的rowkey，默认1000；CACHE每次去取的缓存区大小，默认是10，调整该参数可提高查询速度.例如，查询表t1中的行数，每100条显示一次，缓存区为500 hbase(main)&gt; count ‘t1’,{INTERVAL =&gt; 100, CACHE =&gt; 500}1234&gt; 3）删除数据a )删除行中的某个列值*语法*：``delete &lt;table&gt;, &lt;rowkey&gt;, &lt;family:column&gt; , &lt;timestamp&gt;``,必须指定列名例如：删除表t1，rowkey001中的f1:col1的数据 hbase(main)&gt; delete ‘t1’ ,‘rowkey001’ ,’f1:col1’1234注：将删除改行f1:col1列所有版本的数据b )删除行*语法*：```deleteall &lt;table&gt;, &lt;rowkey&gt;, &lt;family:column&gt; , &lt;timestamp&gt;```，可以不指定列名，删除整行数据例如：删除表t1，rowk001的数据 hbase(main)&gt; deleteall ‘t1’,’rowkey001’1234c）删除表中的所有数据*语法*： ``truncate &lt;table&gt;``其具体过程是：``disable table -&gt; drop table -&gt; create table``例如：删除表t1的所有数据 hbase(main)&gt; truncate ‘t1’123456## **5.Region管理**&gt; 1）移动region*语法*:``move &apos;encodeRegionName&apos;, &apos;ServerName&apos;````encodeRegionName``指的``regioName``后面的编码，``ServerName``指的是``master-status``的``Region Servers``列表示例 hbase(main)&gt;move‘4343995a58be8e5bbc739af1e91cd72d’ ,‘db-41.xxx.xxx.org,60020,1390274516739’12&gt; 2）开启/关闭region*语法*：``balance_switch true|false`` hbase(main)&gt; balance_switch12345&gt; 3）手动split*语法*：``split &apos;regionName&apos;, &apos;splitKey&apos;``&gt; 4）手动触发major compaction*语法*：``Compact all regions in a table:`` hbase&gt; major_compact ‘t1’Compact an entire region:hbase&gt; major_compact ‘r1’Compact a single column family within a region:hbase&gt; major_compact ‘r1’, ‘c1’Compact a single column family within a table:hbase&gt; major_compact ‘t1’, ‘c1’12## **6.配置管理及节点重启**&gt; 1）修改hdfs配置hdfs配置位置： /etc/hadoop/conf` 同步hdfs配置cat /home/hadoop/slaves | xargs -i -t scp /etc/hadoop/conf/hdfs-site.xml hadoop@{}: /etc/hadoop/conf/hdfs-site.xml关闭：cat /home/hadoop/slaves | xargs -i -t ssh hadoop@{} “sudo /home/hadoop/cdh4/hadoop-2.0.0-cdh4.2.1/sbin/hadoop-daemon.sh –config /etc/hadoop/conf stop datanode”启动：cat /home/hadoop/slaves | xargs -i -t ssh hadoop@{} “sudo /home/hadoop/cdh4/hadoop-2.0.0-cdh4.2.1/sbin/hadoop-daemon.sh –config /etc/hadoop/conf start datanode” 2）修改hbase配置hbase配置位置：同步hbase配置cat /home/hadoop/hbase/conf/regionservers | xargs -i -t scp /home/hadoop/hbase/conf/hbase-site.xml hadoop@{}:/home/hadoop/hbase/conf/hbase-site.xmlgraceful重启cd ~/hbase bin/graceful_stop.sh --restart --reload --debug inspurXXX.xxx.xxx.org","categories":[{"name":"数据库","slug":"数据库","permalink":"http://blog.fbi.st/categories/数据库/"}],"tags":[{"name":"Hadoop","slug":"Hadoop","permalink":"http://blog.fbi.st/tags/Hadoop/"}]},{"title":"php实现快速排序算法","slug":"php实现快速排序算法","date":"2018-03-12T02:35:11.000Z","updated":"2019-12-27T04:39:24.011Z","comments":true,"path":"2018/03/12/php实现快速排序算法/","link":"","permalink":"http://blog.fbi.st/2018/03/12/php实现快速排序算法/","excerpt":"快速排序由C. A. R. Hoare在1960年提出。 基本思想通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列. 快速排序又是一种分而治之思想在排序算法上的典型应用。本质上来看，快速排序应该算是在冒泡排序基础上的递归分治法。","text":"快速排序由C. A. R. Hoare在1960年提出。 基本思想通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列. 快速排序又是一种分而治之思想在排序算法上的典型应用。本质上来看，快速排序应该算是在冒泡排序基础上的递归分治法。 算法复杂度在平均状况下，排序 n 个项目要 Ο(nlogn) 次比较。在最坏状况下则需要 Ο(n2) 次比较，但这种状况并不常见。事实上，快速排序通常明显比其他 Ο(nlogn) 算法更快，因为它的内部循环（inner loop）可以在大部分的架构上很有效率地被实现出来。 示意图 动态图 PHP实现123456789101112131415161718192021222324252627function quickSort($arr)&#123; # 数组总数小于1时候返回本身 if (count($arr) &lt;= 1) return $arr; # 随机选取一个中间数 $middle = $arr[0]; $leftArray = array(); $rightArray = array(); for ($i = 1; $i &lt; count($arr); $i++) &#123; if ($arr[$i] &gt; $middle) # 小于中间数放到左边 $rightArray[] = $arr[$i]; else # 大于中间数放到右边 $leftArray[] = $arr[$i]; &#125; ## 左边递归 $leftArray = quickSort($leftArray); ## 加入中间数 $leftArray[] = $middle; $rightArray = quickSort($rightArray); return array_merge($leftArray, $rightArray);&#125;","categories":[{"name":"php","slug":"php","permalink":"http://blog.fbi.st/categories/php/"}],"tags":[{"name":"php","slug":"php","permalink":"http://blog.fbi.st/tags/php/"}]},{"title":"2018_应该静下来","slug":"2018-应该静下来","date":"2018-02-27T14:32:35.000Z","updated":"2019-12-26T09:09:44.348Z","comments":true,"path":"2018/02/27/2018-应该静下来/","link":"","permalink":"http://blog.fbi.st/2018/02/27/2018-应该静下来/","excerpt":"写下这个日志标题的时候还是三月份。开始写内容的时候已经是6月了。 现在还清楚的记得那个时候的心情：早期的项目由于当时能力问题和当时认知的限制，留下了很多bug，客户提出来需要升级。我在其中感受到了一些不满意。晚上下班后的我心情有些低落。思来想去，决定痛改这个项目，并暗自告诉自己。以后再也不写烂代码了。同时也告诉自己，这一年应该静下心来，好好的审视自己，好好的充实自己。","text":"写下这个日志标题的时候还是三月份。开始写内容的时候已经是6月了。 现在还清楚的记得那个时候的心情：早期的项目由于当时能力问题和当时认知的限制，留下了很多bug，客户提出来需要升级。我在其中感受到了一些不满意。晚上下班后的我心情有些低落。思来想去，决定痛改这个项目，并暗自告诉自己。以后再也不写烂代码了。同时也告诉自己，这一年应该静下心来，好好的审视自己，好好的充实自己。 不知不觉过了三个月，当时的感受还在，但心情又有所不同。这三个月里，我扔掉了之前的“烂代码”，重构了该项目。这三个月，每次写代码都会想起自己当时心里立下的那个flag：以后再也不写烂代码了。当然，我很清楚，我肯定又写了很多以后的我眼中的“烂代码”。但这个时候，却是有所不同。 我知道，未来的我会否定我现在的这些“烂代码”，但一定不会否定我现在认真的态度。这段时间，我抱着一个敬畏的心态去写下我每行代码。也抱着敬畏的心情去过好生活。突然发现，自己好像静下来了。 再说说，2018。过了今年，会完成大家口中的人生几件大事。父母渐渐变老。家里的事情也要慢慢抗在我身上了。 想起2008的“年少才轻狂”，好像年少轻狂的年纪已经过去了。奔向而立之年的我，应该静下来，看清自己的位置，看清自己的方向，静下来，抛弃轻浮，静下来稳步往前。 三个月前的立下的flag我会一留着，时刻告诉自己：别写烂代码，好好生活。","categories":[{"name":"live","slug":"live","permalink":"http://blog.fbi.st/categories/live/"}],"tags":[{"name":"生活","slug":"生活","permalink":"http://blog.fbi.st/tags/生活/"}]},{"title":"《楚门的世界》，关于选择和自由","slug":"《楚门的世界》，关于选择和自由","date":"2018-01-22T02:54:04.000Z","updated":"2019-12-26T09:09:17.012Z","comments":true,"path":"2018/01/22/《楚门的世界》，关于选择和自由/","link":"","permalink":"http://blog.fbi.st/2018/01/22/《楚门的世界》，关于选择和自由/","excerpt":"电影相关楚门的世界（The Truman Show） 内容简介楚门是一个平凡得不能再平凡的人，除了一些有些稀奇的经历之外——初恋女友突然失踪、溺水身亡的父亲忽然似乎又出现在眼前，他和绝大多数30多岁的美国男人绝无异样。这令他倍感失落。他也曾试过离开自己生活了多年的地方，但总因种种理由而不能成行。 直到有一天，他忽然发觉自己似乎一直在被人跟踪，无论他走到哪里，干什么事情。这种感觉愈来愈强烈。楚门决定不惜一切代价逃离这个他生活了30多年的地方，去寻找他的初恋女友。 关于金·凯瑞(Jim Carrey)在看这部电影之前，我看到的金凯瑞的作品都还是《变相怪杰》、神探飞机头之类的无厘头喜剧电影。通过这部电影，重新认识了他。电影中塑造的“楚门”形象让人映像深刻。","text":"电影相关楚门的世界（The Truman Show） 内容简介楚门是一个平凡得不能再平凡的人，除了一些有些稀奇的经历之外——初恋女友突然失踪、溺水身亡的父亲忽然似乎又出现在眼前，他和绝大多数30多岁的美国男人绝无异样。这令他倍感失落。他也曾试过离开自己生活了多年的地方，但总因种种理由而不能成行。 直到有一天，他忽然发觉自己似乎一直在被人跟踪，无论他走到哪里，干什么事情。这种感觉愈来愈强烈。楚门决定不惜一切代价逃离这个他生活了30多年的地方，去寻找他的初恋女友。 关于金·凯瑞(Jim Carrey)在看这部电影之前，我看到的金凯瑞的作品都还是《变相怪杰》、神探飞机头之类的无厘头喜剧电影。通过这部电影，重新认识了他。电影中塑造的“楚门”形象让人映像深刻。 观影后感关于电影站在电影拍摄年代看，这部电影的想法大胆，某种程度还“预言”了现在的直播行业。楚门算是直播界的鼻祖吧？电影中很多重复的镜头和场景，但电影情节设计合理，所以在观看的时候注意力也一直比较集中，不会有疲劳。关于电影中的人物：楚门。他积极乐观，从小到大的几十年的生活直播，鼓舞了电影中很多“电视机前的观众”。最后选择离开“楚门的世界”的勇敢，也鼓舞了很多我这个看电影的观众。 我的感受我们世界，楚门的世界看完电影的时候，我会有一个疑惑：我是不是也处在一“XX的世界”？转瞬又会笑自己想多了。但再认真的思考一下又会发现事情并不简单（细思极恐）：我真的处在一个真实的世界里么？我们看楚门，会不会也有人正在看着我们？（想得有点多啊，哈哈）电影中，我们看得到的是：楚门走出了他的世界。生活中，我们看不到的是：我们走不出自己的世界。虽然我们不会真的在一场直播中，但我们的确被困在了自己的世界中。很多时候，我们都会计较生活中的点滴得失。我们会恐惧去改变。身体虽然没有被禁锢，但灵魂却甘心在“楚门的世界”中安逸。 关于自由和选择电影中，楚门走出了“直播世界”，获得了自由，看起来是如此。可是我认为楚门在出门之前就已经获得了自由。我认为，自由的概念不是“无拘无束”，而是“有得选”，也就是有选择的权利。楚门在出门前的那一刻，他是有选择走出去还是留下的权利，所以在这一刻，他是自由的。他知道了真相后，无论是留在电影世界，还是走出去，这件事情上，他都已经获得了“自由”。我对自由最直观感受到的是在第一次搭上梯子翻出去的那一刻，一瞬间，我好像获得了某种自由。因为我终于可以选择是选用百度还是google，我是选择优酷还是youtube。有点不可思议，但就是这么简单。自由好像就是这样，在你有选择的那一刻，你就有自由。你可以选择去旅行还是宅家里，监狱里的囚徒不行。这么想，好像是有点道理。 最后： 如果我再也见不到你，我会祝你早安、午安还有晚安。","categories":[{"name":"live","slug":"live","permalink":"http://blog.fbi.st/categories/live/"}],"tags":[{"name":"生活","slug":"生活","permalink":"http://blog.fbi.st/tags/生活/"},{"name":"电影","slug":"电影","permalink":"http://blog.fbi.st/tags/电影/"}]},{"title":"看电影《十二怒汉》","slug":"看电影《十二怒汉》","date":"2017-12-28T09:36:53.000Z","updated":"2019-12-26T09:55:55.602Z","comments":true,"path":"2017/12/28/看电影《十二怒汉》/","link":"","permalink":"http://blog.fbi.st/2017/12/28/看电影《十二怒汉》/","excerpt":"相关介绍十二怒汉 12 Angry Men (1957) 剧情简介一个在贫民窟长大的18岁少年因为涉嫌杀害自己的父亲被告上法庭，证人言之凿凿，各方面的证据都对他极为不利。十二个不同职业的人组成了这个案件的陪审团，他们要在休息室达成一致的意见，裁定少年是否有罪，如果罪名成立，少年将会被判处死刑。 十二个陪审团成员各有不同，除了8号陪审员（H enry Fonda 饰）之外，其他人对这个犯罪事实如此清晰的案子不屑一顾，还没有开始讨论就认定了少年有罪。8号陪审员提出了自己的“合理疑点”，耐心地说服其他的陪审员，在这个过程中，他们每个人不同的人生观也在冲突和较量……","text":"相关介绍十二怒汉 12 Angry Men (1957) 剧情简介一个在贫民窟长大的18岁少年因为涉嫌杀害自己的父亲被告上法庭，证人言之凿凿，各方面的证据都对他极为不利。十二个不同职业的人组成了这个案件的陪审团，他们要在休息室达成一致的意见，裁定少年是否有罪，如果罪名成立，少年将会被判处死刑。 十二个陪审团成员各有不同，除了8号陪审员（H enry Fonda 饰）之外，其他人对这个犯罪事实如此清晰的案子不屑一顾，还没有开始讨论就认定了少年有罪。8号陪审员提出了自己的“合理疑点”，耐心地说服其他的陪审员，在这个过程中，他们每个人不同的人生观也在冲突和较量…… 观影有感关于电影在看本片之前，我在网上看到过有人总结：“那些因为名字而被错过的电影”，我记得其中就有印度电影《三傻大闹宝莱坞》。我不记得其中是否有这部《十二怒汉》，但我知道我在很长一段时间内错过这部电影就是因为他的名字。“十二怒汉” 这个名字给我的第一感觉好像是类似“三百斯巴达勇士”一样，而我并不太喜欢这类型的电影。 至于，后面拿起这部电影看的原因是是在逛b站的时候，看到介绍这部电影的一个视频。通过那段视频我简单的了解了这部电影。然后找了一个周末的晚上，仔细观赏了这部电影。 由于拍摄年代比较久远，所以是黑白的。但这丝毫不影响导演和演员在黑白光影之间，讲述形象、深刻的故事。 不谈剧情，整个电影的一个半小时剧情，除了开场和结束的几个镜头，整个故事其余镜头都是在一个带洗手间的会议室中完成的。故事讲述得丝丝入扣，导演的才华和演员的演技，在这单调到离谱的场景中展现的淋漓尽致。 关于整部电影，有人说这是一部伟大的电影，我个人觉得，这部电影绝对对得住“伟大”两个字。非常推荐一看。 我的感受关于决策整部电影，最让我印象深刻的地方是当所有人都在选择“赞同”的时候，8号陪审员站出来选择“不赞同”。心理学上，有我们很熟悉的一个现象，叫“从众效应”，在很多时候，我们更喜欢，更愿意，站在大多数的一方。买东西时，我们会选择销量好的，在舆论方面，我们跟愿意去关注大家都关注的事物。 8号评审员在“证据确凿”，除了自己外11个成员都投“赞成票”的情况下，勇敢的投出“反对票”，并阐述自己的观点。 我不禁想到自己在做决策时候，我是否有勇气去做出这样的“投票”。在遇到大多数人反对自己观点的时候，我是否能坚持自己的想法，能坚持的与他辩论。我知道，很多时候这个答案都是否定的，这值得我去反思。 关于态度关于对待事情的态度，这个要从人物的关系说起。陪审团的成员都与他们所讨论的男孩在生活上是没有任何关系的。所以他们大多数人开始也并不太在乎他的生死。也不会在心里为男孩做辩解。这也是开始他对小男孩这件事情的一个态度。 轻视的态度决定了，11位评审员不会深入的去思考整件事情，更加不会站在为小男孩辩解的角度去思考，因为这跟‘我’无关。 当然，也正是因为他们对小男孩的态度是一种事不关己的态度，一种没有态度的态度，所以他们后面才能做到轻易的转换思路，为小男孩找到合理的解释。 对待事情的态度决定，我们对事情的思考方式，从何决定了我们的行为。所以表明态度，要谨慎。 关于生命影片中，小男孩失去了父亲，也没有出现过他的母亲。除了8号评审员，片中出现的人物几乎没有人在意小男孩的生命。假如评审团中没有出现8号评审员，小男孩被判死刑，估计世界上也不会有人为他心痛，一个月后，一年以后，也不会有人记得世界上有小男孩这样一个人出现过。 包括，片中指认小男孩的老人，一生没有什么作为，到死去之前也不会有人注意到他。 这让我想到了电影《嫌疑人X的献身》中被数学家杀死的流浪汉，他的死去没有给世界带来丝毫的影响。 我还想到了很多死去的伟人，他们的逝去得到了整个世界的关注。他们的生命在这个星球上留下了不可磨灭的印记。 生命就是这样的神奇，可以灿烂如星空，也可以平淡如水滴。 还有很多影片看完了，这篇简短的观后感也差不多结束了。由于文字水平有限，也可能是很多东西没有体悟透彻，所以漏掉了很多。影片和文字结束了，但生活还在继续，我相信，这部电影收获的更多的东西，是我现在在没有感受到的，没有讲述出来的，他会无形的影响着我今后的生活，生活会越来越好。 其他电影也是，其他书籍也是。","categories":[{"name":"live","slug":"live","permalink":"http://blog.fbi.st/categories/live/"}],"tags":[{"name":"生活","slug":"生活","permalink":"http://blog.fbi.st/tags/生活/"},{"name":"电影","slug":"电影","permalink":"http://blog.fbi.st/tags/电影/"}]},{"title":"处理php脚本超时的各种尝试","slug":"处理php脚本超时的各种尝试","date":"2017-12-15T08:04:07.000Z","updated":"2019-12-26T09:54:43.215Z","comments":true,"path":"2017/12/15/处理php脚本超时的各种尝试/","link":"","permalink":"http://blog.fbi.st/2017/12/15/处理php脚本超时的各种尝试/","excerpt":"php配置方面的调整 php代码中的调整 1234&lt;?php ignore_user_abort(); set_time_limit(0);?&gt;","text":"php配置方面的调整 php代码中的调整 1234&lt;?php ignore_user_abort(); set_time_limit(0);?&gt; php配置文件的修改 12#/usr/local/php/etc/php.inimax_execution_time = 0 php-fpm.conf 参数 1request_terminate_timeout = 0 设置单个请求的超时中止时间. 该选项可能会对php.ini设置中的’max_execution_time‘因为某些特殊原因没有中止运行的脚本有用. 设置为 ‘0‘ 表示 ‘Off‘. 当经常出现502错误时可以尝试更改此选项。request_slowlog_timeout = 10s 当一个请求该设置的超时时间后，就会将对应的PHP调用堆栈信息完整写入到慢日志中. 设置为 ‘0‘ 表示 ‘Off‘ Nginx方面的调整nginx如果要解析php脚本语言，就必须通过配置fastcgi模块来提供对php支持 1. fast_cgi的配置fastcgi_connect_timeout 配置语法： fastcgi_connect_timeout 时间(单位为s) 默认值： fastcgi_connect_timeout 60s 配置区域： http server location 配置项说明： 指定nginx与后端fastcgi server连接超时时间 --- fastcgi_send_timeout 配置语法： fastcgi_send_timeout 时间(单位为s) 默认值： fastcgi_send_timeout 60s; 配置区域： http server location 配置项说明：指定nginx向后端传送请求超时时间（指已完成两次握手后向fastcgi传送请求超时时间）","categories":[{"name":"php","slug":"php","permalink":"http://blog.fbi.st/categories/php/"}],"tags":[{"name":"php","slug":"php","permalink":"http://blog.fbi.st/tags/php/"}]},{"title":"前端分页逻辑的思考","slug":"前端分页逻辑的思考","date":"2017-06-01T14:59:42.000Z","updated":"2019-12-26T09:19:16.836Z","comments":true,"path":"2017/06/01/前端分页逻辑的思考/","link":"","permalink":"http://blog.fbi.st/2017/06/01/前端分页逻辑的思考/","excerpt":"/* 今天偶有空闲，于是便想把之前随意放上的一段代码做个解释。 其实以现在的角度（过去了两三个月）来看这个标题，明显感觉有点装逼了。 主要原因是这个简单的问题还算不上思考 不过既然都写了，就继续装下去吧。 */","text":"/* 今天偶有空闲，于是便想把之前随意放上的一段代码做个解释。 其实以现在的角度（过去了两三个月）来看这个标题，明显感觉有点装逼了。 主要原因是这个简单的问题还算不上思考 不过既然都写了，就继续装下去吧。 */先上代码,项目里抽取的一段,基于tp的.主要看思路. 代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;div class=\"pages\"&gt; &lt;if condition=\"$totalPage eq 1\"&gt; &lt;!-- 只用一页的情况 --&gt; &lt;a href=\"/page/1\"&gt;1&lt;/a&gt; &lt;elseif condition=\"($totalPage gt 1) AND ($totalPage elt 8)\"/&gt;&lt;!-- 总页数是2到8也的情况 --&gt; &lt;if condition=\"$page eq 1\"&gt; &lt;!-- 当前页是1的情况 --&gt; &lt;for start=\"1\" end=\"$totalPage+1\"&gt; &lt;a href=\"/page/&#123;$i&#125;\"&gt;&#123;$i&#125;&lt;/a&gt; &lt;/for&gt; &lt;a href=\"/page/&#123;$page+1&#125;\"&gt;下一页&lt;/a&gt; &lt;elseif condition=\"$page eq $totalPage \"/&gt;&lt;!-- 当前页是最后一页的情况 --&gt; &lt;a href=\"/page/&#123;$page-1&#125;\"&gt;上一页&lt;/a&gt; &lt;for start=\"1\" end=\"$totalPage+1\"&gt; &lt;a href=\"/page/&#123;$i&#125;\"&gt;&#123;$i&#125;&lt;/a&gt; &lt;/for&gt; &lt;else /&gt;&lt;!-- 其他(不等于第一和最后一页的)情况 --&gt; &lt;a href=\"/page/&#123;$page-1&#125;\"&gt;上一页&lt;/a&gt; &lt;for start=\"1\" end=\"$totalPage+1\"&gt; &lt;a href=\"/page/&#123;$i&#125;\"&gt;&#123;$i&#125;&lt;/a&gt; &lt;/for&gt; &lt;a href=\"/page/&#123;$page+1&#125;\"&gt;下一页&lt;/a&gt; &lt;/if&gt; &lt;elseif condition=\"$totalPage egt 8\"/&gt; &lt;if condition=\"$page eq 1\"&gt; &lt;!-- 当前页是1的情况 --&gt; &lt;for start=\"1\" end=\"9\"&gt; &lt;a href=\"/page/&#123;$i&#125;\"&gt;&#123;$i&#125;&lt;/a&gt; &lt;/for&gt; &lt;a href=\"/page/&#123;$page+1&#125;\"&gt;下一页&lt;/a&gt; &lt;elseif condition=\"($page gt 1) AND ($page lt 5)\"/&gt; &lt;!-- 当前页是2-4的情况 --&gt; &lt;a href=\"/page/&#123;$page-1&#125;\"&gt;上一页&lt;/a&gt; &lt;for start=\"1\" end=\"9\"&gt; &lt;a href=\"/page/&#123;$i&#125;\"&gt;&#123;$i&#125;&lt;/a&gt; &lt;/for&gt; &lt;a href=\"/page/&#123;$page+1&#125;\"&gt;下一页&lt;/a&gt; &lt;elseif condition=\"($page egt 5) AND ($page elt ($totalPage-3))\"/&gt;&lt;!-- 当前页是5-倒数第4的情况 --&gt; &lt;a href=\"/page/&#123;$page-1&#125;\"&gt;上一页&lt;/a&gt; &lt;for start=\"(-4)\" end=\"4\"&gt; &lt;a href=\"/page/&#123;$page+$i&#125;\"&gt;&#123;$page+$i&#125;&lt;/a&gt; &lt;/for&gt; &lt;a href=\"/page/&#123;$page+1&#125;\"&gt;下一页&lt;/a&gt; &lt;elseif condition=\"$page eq $totalPage\"/&gt; &lt;!-- 当前页是最后一页情况 --&gt; &lt;a href=\"/page/&#123;$page-1&#125;\"&gt;上一页&lt;/a&gt; &lt;for start=\"-7\" end=\"1\"&gt; &lt;a href=\"/page/&#123;$page+$i&#125;\"&gt;&#123;$page+$i&#125;&lt;/a&gt; &lt;/for&gt; &lt;elseif condition=\"$page gt ($totalPage-3)\"/&gt;&lt;!--当前页大于最大页数-3且不等于最大页数的情况。--&gt; &lt;a href=\"/page/&#123;$page-1&#125;\"&gt;上一页&lt;/a&gt; &lt;for start=\"($totalPage-$page)-7\" end=\"($totalPage-$page)+1\"&gt; &lt;a href=\"/page/&#123;$page+$i&#125;\"&gt;&#123;$page+$i&#125;&lt;/a&gt; &lt;/for&gt; &lt;a href=\"/page/&#123;$page+1&#125;\"&gt;下一页&lt;/a&gt; &lt;/if&gt; &lt;/if&gt; &lt;/div&gt; 其实在备注中已经很明显了。分为以下几种情况，总页面数： 1.总页数只有一页的情况 假设总页数只有1页的话，当前页肯定是1，且没有上一页或下一页 2.总页数2页到8页的情况（假设共显示八页） 首先，总页数小于8的话，所有的页面都应该显示。直接用for循环到最大页数。 这种情况下，假设当前页是1的话，就没有上一页，有下一页。假设当前页是最后一页的话，有上一页，但是没有下一页。其他情况下就是上一页和下一页都有。 3.总页数大于8页的情况 这种情况稍微复杂，因为需要控制页面的输出 假设当前页是1到5页的情况，显示的是1-8页。并且，当前页是1的情况没有上一页。 分离出来就是：当前页为1的情况：没有上一页，有下一页，显示1-8页， 当前页为2-5的情况，有上一页和下一页，显示1-8页， 那么当页码大于5页的时候呢？？这个时候就需要考虑到三种种情况， 当前页小于最大页数-3的情况，这个情况下，就显示当前页-4页到当前页+3页。 当前页大于最大页数-3且不等于最大页数的情况。 当前页是最大页数的情况。 这三种情况总结一下就是： 显示上一页和下一页，页码是当前页-4页到当前页+3页 显示上一页和下一页，显示当前（页总页数-当前页）-7 到（总页数-当前页）+1 ps：这种情况稍微要奇怪 显示上一页，不显示下一页，（显示当前页-8）到 当前页。","categories":[{"name":"php","slug":"php","permalink":"http://blog.fbi.st/categories/php/"}],"tags":[{"name":"php","slug":"php","permalink":"http://blog.fbi.st/tags/php/"}]},{"title":"mysql数据库导入/导出(总结备忘)","slug":"mysql数据库导入、导出(总结备忘)","date":"2017-05-20T12:07:31.000Z","updated":"2019-12-26T10:07:43.494Z","comments":true,"path":"2017/05/20/mysql数据库导入、导出(总结备忘)/","link":"","permalink":"http://blog.fbi.st/2017/05/20/mysql数据库导入、导出(总结备忘)/","excerpt":"在linux下直接用命令行操作就可以 在windows下 一般情况下有两种方法一个也是用命令行 另一个是用phpmyadmin 1.phpmyadmin先来说说phpmyadmin 这个工具导出和导入很简单 而且导入时无需建库 直接还原成原来的数据库 用 source 也可以还原 但他导入文件时有大小限制不能超过20M","text":"在linux下直接用命令行操作就可以 在windows下 一般情况下有两种方法一个也是用命令行 另一个是用phpmyadmin 1.phpmyadmin先来说说phpmyadmin 这个工具导出和导入很简单 而且导入时无需建库 直接还原成原来的数据库 用 source 也可以还原 但他导入文件时有大小限制不能超过20M 再来说说 mysqldump 和 source 用命令操作很快 但是想把导出的文件再导入时必须先建立一个数据库(这个库可以随便起名) 然后进入数据库后才能导入用phpmyadmin导入 mysqldump 导出的文件也得需要这步 2.其他命令方式下面是从前辈那copy来的命令具体使用方法1.导出整个数据库1mysqldump -u 用户名 -p 数据库名 &gt; 导出的文件名 1mysqldump -uroot -proot dingding &gt; 1.sql 2.导出一个表1mysqldump -u 用户名 -p 数据库名 表名&gt; 导出的文件名 1mysqldump -uroot -proot dingding &gt;F:/dingding/wcnc.sql 3.导出一个数据库结构1mysqldump -u wcnc -p -d --add-drop-table smgp_apps_wcnc &gt;d:wcnc_db.sql -d 没有数据 –add-drop-table 在每个create语句之前增加一个drop table 备忘: mysqldump在linux下可直接使用 在windows下有时需要进入mysql/bin中使用 因为有时用的是类似appserv的套装软件 这样的话命令就不能直接使用 因为这些命令没在环境变量的目录里 而且用mysqldump导出的备份 必须先建立数据库才能导入 4.导入数据库 常用source命令 进入mysql数据库控制台， 如mysql -u root -p mysql&gt;use 数据库 然后使用source命令，后面参数为脚本文件(如这里用到的.sql) mysql&gt;source d:wcnc_db.sql 存疑: phpmyadmin导入有大小限制 不知道source导入时有没限制 而且导出时是不可以限制文件大小 并且分数个文件导出","categories":[{"name":"数据库","slug":"数据库","permalink":"http://blog.fbi.st/categories/数据库/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://blog.fbi.st/tags/Mysql/"},{"name":"数据库","slug":"数据库","permalink":"http://blog.fbi.st/tags/数据库/"}]},{"title":"WinSCP连接linux遇到的一个小问题","slug":"WinSCP连接linux遇到的一个小问题","date":"2017-05-20T12:07:31.000Z","updated":"2019-12-26T10:10:35.476Z","comments":true,"path":"2017/05/20/WinSCP连接linux遇到的一个小问题/","link":"","permalink":"http://blog.fbi.st/2017/05/20/WinSCP连接linux遇到的一个小问题/","excerpt":"第一次在win上使用WinSCP来链接linux，遇到的一个小问题：提示我： 1服务器拒绝了sftp连接，但它监听ftp连接.想要用ftp协议来代替sftp 然后我将链接方式改成了ftp。又爆出另一个蛋疼的提示：1由于目标机器积极拒绝，无法连接","text":"第一次在win上使用WinSCP来链接linux，遇到的一个小问题：提示我： 1服务器拒绝了sftp连接，但它监听ftp连接.想要用ftp协议来代替sftp 然后我将链接方式改成了ftp。又爆出另一个蛋疼的提示：1由于目标机器积极拒绝，无法连接 两个提示都百度了一下，果然有很多答案，说是要关防火墙啊，改连接方式啊等等。满世界的答案都成功的避开了我遇到的问题。 纠结了很久，我考虑到WinSCP连接linux的原理是什么呢？再仔细想想自己哪一步可能漏掉？？ 突然想起，这是自己新装的一个虚拟机，还没配SSH，难道是这个原因？？ 果断的配上了SSH，发现果然OK了。果断的记录一下，如果也有新手跟我遇到同样的问题，就能有所帮助。 关于SSH可以参考另一篇文章：SSH原理和运用","categories":[{"name":"tools","slug":"tools","permalink":"http://blog.fbi.st/categories/tools/"}],"tags":[{"name":"tools","slug":"tools","permalink":"http://blog.fbi.st/tags/tools/"},{"name":"Linux","slug":"Linux","permalink":"http://blog.fbi.st/tags/Linux/"}]},{"title":"Elasticsearch非权威指南，写在开始的话","slug":"写在开始的话","date":"2017-05-20T12:07:31.000Z","updated":"2019-06-04T00:42:36.000Z","comments":true,"path":"2017/05/20/写在开始的话/","link":"","permalink":"http://blog.fbi.st/2017/05/20/写在开始的话/","excerpt":"打算了好久，《elasticsearch非权威指南》今天终于开始写了。 距离开始接触elasticsearch到今天开始写这个笔记有半年多了。从开始的完全蒙圈到现在的懵懵懂懂。踩过N多的坑。开始写这个《指南》主要有下面几个原因：","text":"打算了好久，《elasticsearch非权威指南》今天终于开始写了。 距离开始接触elasticsearch到今天开始写这个笔记有半年多了。从开始的完全蒙圈到现在的懵懵懂懂。踩过N多的坑。开始写这个《指南》主要有下面几个原因： ##一、能帮到一些开始学习ES的人 首先，我自己是一个人独自的百度、google学习过来的。es是一个比较新的东西，网上的中文资料很有限。而且本人是做php开发的，es是基于lucene的，是用java开发的，所以php的资料就更少了。 在学习的过程中我真的是爬过超多的坑，所以希望记录下这些“坑”，能帮助一些开始学习ES的人，后面的人少跳一些坑，我自己也希望有个人能在我跳坑之前提醒我，虽然都已经过去了。 ##二、希望帮助自己理清学到的东西 我开始写这个《指南》并不是说我现在玩ES玩得多好，相反，我的对ES的了解才刚刚开始。我希望通过写下笔记的形式理清自己的知识节点。将之前学到的东西串起来，看自己哪有漏洞，再去边补边写。所以，这个《指南》肯定有很多的错误的和不足，希望发现的朋友能帮忙指出，不胜感激。 也是因为本人目前技术有限的原因，本笔记的内容也写不了很深入，我自己yy的认为，这可能会让这个《指南》更加”亲民易懂“，更适合新人。 ##三、感谢在我学习过程中帮助过我的朋友。 学习过程中我遇到许多的问题，很多问题度娘和gg都找不到，所以只能求助万能的群有和论坛的朋友。过程中，很多朋友帮我解答过很多的问题。 每次我的问题得到解答的时候，我都暗暗的告诉自己，这是一种”接力“，当我得到答案的时候，就是我拿到“接力棒”的时候，我有义务将“它”，传下去。所以遇到我能解决的问题，我一定乐意去帮别人解决。我将这当做感谢那些帮助过我的人的方式。 关于笔记的几点说明： 由于本人对php比较熟悉，但在学习es的过程中顺便学了点java，所以关于涉及到代码的地方，我会用curl、php和java三种方式实现（特殊情况特殊说明）。 对于ES本人也是新手，所以笔记会不断的完善。 整个《指南》肯定会涉及到一些其他地方找到的资料，我会尽量的表明出处，如果有遗漏，有侵权的，请提醒，一定及时删改。 《elasticsearch非权威指南》目录本笔记欢迎转载，欢迎分享，转载分享不用通知作者。不过，如果可以的话希望能注明出处，看完文章还能点个赞。","categories":[{"name":"Elasticsearch非权威指南","slug":"Elasticsearch非权威指南","permalink":"http://blog.fbi.st/categories/Elasticsearch非权威指南/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://blog.fbi.st/tags/Elasticsearch/"}]},{"title":"Elasticsearch简介","slug":"elasticsearch简介","date":"2017-05-20T12:07:31.000Z","updated":"2019-12-26T10:05:57.910Z","comments":true,"path":"2017/05/20/elasticsearch简介/","link":"","permalink":"http://blog.fbi.st/2017/05/20/elasticsearch简介/","excerpt":"一、elasticsearch是什么 ElasticSearch是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。(百度百科)","text":"一、elasticsearch是什么 ElasticSearch是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。(百度百科) 理解这段话简单理解就是：ES是一个搜索引擎，是基于Lucene的。它是一个提供了基于RESTful 的web接口，能够达到实时，稳定，可靠，快速的搜索引擎。 Elasticsearch也使用Java开发并使用Lucene作为其核心来实现所有索引和搜索的功能，但是它的目的是通过简单的RESTful API来隐藏Lucene的复杂性，从而让全文搜索变得简单。 ES是开源的，它的官网是：www.elastic.co， github项目地址是：www.github.com/elastic/elasticsearch 中文论坛：elasticsearc.cn 二、elasticsearch能做什么Elasticsearch不仅仅是Lucene和全文搜索，其他特点还包括： 分布式的实时文件存储，每个字段都被索引并可被搜索 分布式的实时分析搜索引擎 可以扩展到上百台服务器，处理PB级结构化或非结构化数据 而且，所有的这些功能被集成到一个服务里面，你的应用可以通过简单的RESTful API、各种语言的客户端甚至命令行与之交互。总结一句话：ES是一个功能强大，使用简单的分布式的全文搜索引擎。 三、elasticsearch文档的概念在Elasticsearch中，数据是以文档(document)形式存在的，归属于一种类型(type),而这些类型存在于索引(index)。和关系型数据库中的概念对比： SQL database table row column elasticsearch index type document field 其实这样的对比并不是完全的准确的，但是有助于我们理解elasticsearch的数据存储格式。 四、个人对ES的一些理解elasticsearch主要优势是：速度快，使用方便，分布式的，功能强大。ES官方的想做的是ELK结合起来做日志分析等工作。估计这也是它最多的应用场景。ES使用非常方便，官方文档也比较全，社区也很活跃。估计以后的发展会越来越好，应用场景会越来越多。 关于更详细的ES简介可以查看网上有朋友翻译的《Elasticsearch权威指南》也可以看看这个朋友写的ES基本概念：Elasticsearch学习，请先看这一篇！ 《elasticsearch非权威指南》目录本笔记欢迎转载，欢迎分享，转载分享不用通知作者。不过，如果可以的话希望能注明出处，看完文章还能点个赞。","categories":[{"name":"Elasticsearch非权威指南","slug":"Elasticsearch非权威指南","permalink":"http://blog.fbi.st/categories/Elasticsearch非权威指南/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://blog.fbi.st/tags/Elasticsearch/"}]},{"title":"SSH的原理和运用","slug":"SSH的原理和运用","date":"2017-05-20T12:07:31.000Z","updated":"2019-12-27T09:29:24.186Z","comments":true,"path":"2017/05/20/SSH的原理和运用/","link":"","permalink":"http://blog.fbi.st/2017/05/20/SSH的原理和运用/","excerpt":"SSH(安全外壳协议) 为 Secure Shell 的缩写，由 IETF 的网络小组（Network Working Group）所制定；SSH 为建立在应用层和传输层基础上的安全协议。SSH 是目前较可靠，专为远程登录会话和其他网络服务提供安全性的协议。利用 SSH 协议可以有效防止远程管理过程中的信息泄露问题。SSH最初是UNIX系统上的一个程序，后来又迅速扩展到其他操作平台。SSH在正确使用时可弥补网络中的漏洞。SSH客户端适用于多种平台。几乎所有UNIX平台—包括HP-UX、Linux、AIX、Solaris、Digital UNIX、Irix，以及其他平台，都可运行SSH。百度百科:SSH","text":"SSH(安全外壳协议) 为 Secure Shell 的缩写，由 IETF 的网络小组（Network Working Group）所制定；SSH 为建立在应用层和传输层基础上的安全协议。SSH 是目前较可靠，专为远程登录会话和其他网络服务提供安全性的协议。利用 SSH 协议可以有效防止远程管理过程中的信息泄露问题。SSH最初是UNIX系统上的一个程序，后来又迅速扩展到其他操作平台。SSH在正确使用时可弥补网络中的漏洞。SSH客户端适用于多种平台。几乎所有UNIX平台—包括HP-UX、Linux、AIX、Solaris、Digital UNIX、Irix，以及其他平台，都可运行SSH。百度百科:SSH SSH是每一台Linux电脑的标准配置。随着Linux设备从电脑逐渐扩展到手机、外设和家用电器，SSH的使用范围也越来越广。不仅程序员离不开它，很多普通用户也每天使用。SSH具备多种功能，可以用于很多场合。有些事情，没有它就是办不成。本文是我的学习笔记，总结和解释了SSH的常见用法，希望对大家有用。 1.SSH是什么 简单说，SSH是一种网络协议，用于计算机之间的加密登录。如果一个用户从本地计算机，使用SSH协议登录另一台远程计算机，我们就可以认为，这种登录是安全的，即使被中途截获，密码也不会泄露。 二、最基本的用法SSH主要用于远程登录。假定你要以用户名user，登录远程主机host，只要一条简单命令就可以了。1$ ssh user@host 如果本地用户名与远程用户名一致，登录时可以省略用户名。1$ ssh host SSH的默认端口是22，也就是说，你的登录请求会送进远程主机的22端口。使用p参数，可以修改这个端口。1$ ssh -p 2222 user@host 上面这条命令表示，ssh直接连接远程主机的2222端口。 三、中间人攻击SSH之所以能够保证安全，原因在于它采用了公钥加密。整个过程是这样的： （1）远程主机收到用户的登录请求，把自己的公钥发给用户。 （2）用户使用这个公钥，将登录密码加密后，发送回来。 （3）远程主机用自己的私钥，解密登录密码，如果密码正确，就同意用户登录。 这个过程本身是安全的，但是实施的时候存在一个风险：如果有人截获了登录请求，然后冒充远程主机，将伪造的公钥发给用户，那么用户很难辨别真伪。因为不像https协议，SSH协议的公钥是没有证书中心（CA）公证的，也就是说，都是自己签发的。可以设想，如果攻击者插在用户与远程主机之间（比如在公共的wifi区域），用伪造的公钥，获取用户的登录密码。再用这个密码登录远程主机，那么SSH的安全机制就荡然无存了。这种风险就是著名的”中间人攻击”（Man-in-the-middle attack）。 SSH协议是如何应对的呢？ 四、口令登录如果你是第一次登录对方主机，系统会出现下面的提示：$ ssh user@host The authenticity of host &#39;host (12.18.429.21)&#39; can&#39;t be established. RSA key fingerprint is 98:2e:d7:e0:de:9f:ac:67:28:c2:42:2d:37:16:58:4d. Are you sure you want to continue connecting (yes/no)? 这段话的意思是，无法确认host主机的真实性，只知道它的公钥指纹，问你还想继续连接吗？所谓”公钥指纹”，是指公钥长度较长（这里采用RSA算法，长达1024位），很难比对，所以对其进行MD5计算，将它变成一个128位的指纹。上例中是98:2e:d7:e0:de:9f:ac:67:28:c2:42:2d:37:16:58:4d，再进行比较，就容易多了。 很自然的一个问题就是，用户怎么知道远程主机的公钥指纹应该是多少？回答是没有好办法，远程主机必须在自己的网站上贴出公钥指纹，以便用户自行核对。 假定经过风险衡量以后，用户决定接受这个远程主机的公钥。Are you sure you want to continue connecting (yes/no)? yes 系统会出现一句提示，表示host主机已经得到认可。Warning: Permanently added &#39;host,12.18.429.21&#39; (RSA) to the list of known hosts. 然后，会要求输入密码。Password: (enter password) 如果密码正确，就可以登录了。当远程主机的公钥被接受以后，它就会被保存在文件$HOME/.ssh/known_hosts之中。下次再连接这台主机，系统就会认出它的公钥已经保存在本地了，从而跳过警告部分，直接提示输入密码。 每个SSH用户都有自己的known_hosts文件，此外系统也有一个这样的文件，通常是/etc/ssh/ssh_known_hosts，保存一些对所有用户都可信赖的远程主机的公钥。 五、公钥登录使用密码登录，每次都必须输入密码，非常麻烦。好在SSH还提供了公钥登录，可以省去输入密码的步骤。 所谓”公钥登录”，原理很简单，就是用户将自己的公钥储存在远程主机上。登录的时候，远程主机会向用户发送一段随机字符串，用户用自己的私钥加密后，再发回来。远程主机用事先储存的公钥进行解密，如果成功，就证明用户是可信的，直接允许登录shell，不再要求密码。 这种方法要求用户必须提供自己的公钥。如果没有现成的，可以直接用ssh-keygen生成一个：ssh-keygen```12345678 运行上面的命令以后，系统会出现一系列提示，可以一路回车。其中有一个问题是，要不要对私钥设置口令（passphrase），如果担心私钥的安全，这里可以设置一个。运行结束以后，在`$HOME/.ssh/`目录下，会新生成两个文件：`id_rsa.pub`和`id_rsa`。前者是你的公钥，后者是你的私钥。这时再输入下面的命令，将公钥传送到远程主机host上面：```$ ssh-copy-id user@host 好了，从此你再登录，就不需要输入密码了。如果还是不行，就打开远程主机的/etc/ssh/sshd_config这个文件，检查下面几行前面”#”注释是否取掉。RSAAuthentication yes PubkeyAuthentication yes AuthorizedKeysFile .ssh/authorized_keys然后，重启远程主机的ssh服务。 // ubuntu系统 service ssh restart // debian系统 /etc/init.d/ssh restart 六、authorized_keys文件远程主机将用户的公钥，保存在登录后的用户主目录的$HOME/.ssh/authorized_keys文件中。公钥就是一段字符串，只要把它追加在authorized_keys文件的末尾就行了。 这里不使用上面的ssh-copy-id命令，改用下面的命令，解释公钥的保存过程： $ ssh user@host &#39;mkdir -p .ssh &amp;&amp; cat &gt;&gt; .ssh/authorized_keys&#39; &lt; ~/.ssh/id_rsa.pub 这条命令由多个语句组成，依次分解开来看： （1）”$ ssh user@host“，表示登录远程主机； （2）单引号中的mkdir .ssh &amp;&amp; cat &gt;&gt; .ssh/authorized_keys，表示登录后在远程shell上执行的命令： （3）”$ mkdir -p .ssh“的作用是，如果用户主目录中的.ssh目录不存在，就创建一个； （4）&#39;cat &gt;&gt; .ssh/authorized_keys&#39; &lt; ~/.ssh/id_rsa.pub的作用是，将本地的公钥文件~/.ssh/id_rsa.pub，重定向追加到远程文件authorized_keys的末尾。 写入authorized_keys文件后，公钥登录的设置就完成了。 拓展阅读：数字签名是什么？","categories":[{"name":"linux","slug":"linux","permalink":"http://blog.fbi.st/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://blog.fbi.st/tags/linux/"}]},{"title":"Elasticsearch非权威指南目录","slug":"elasticsearch学习笔记目录","date":"2017-05-20T12:07:31.000Z","updated":"2019-12-26T10:06:24.750Z","comments":true,"path":"2017/05/20/elasticsearch学习笔记目录/","link":"","permalink":"http://blog.fbi.st/2017/05/20/elasticsearch学习笔记目录/","excerpt":"#写在开始的话 #一、elasticsearch简介 ##1、ES一些名词的解释","text":"#写在开始的话 #一、elasticsearch简介 ##1、ES一些名词的解释 #二、elasticsearch及各种组件的安装 #三、es索引存储 #四、搜索查询 #五、集群管理 #六、其他","categories":[{"name":"Elasticsearch非权威指南","slug":"Elasticsearch非权威指南","permalink":"http://blog.fbi.st/categories/Elasticsearch非权威指南/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://blog.fbi.st/tags/Elasticsearch/"}]},{"title":"Python，Re模块的学习","slug":"Python，Re模块的学习","date":"2017-05-20T12:07:31.000Z","updated":"2019-12-26T10:08:53.639Z","comments":true,"path":"2017/05/20/Python，Re模块的学习/","link":"","permalink":"http://blog.fbi.st/2017/05/20/Python，Re模块的学习/","excerpt":"1.概念：正则表达式（或 RE）是一种小型的、高度专业化的编程语言，在Python中）它内嵌在Python中，并通过 re 模块实现。使用这个小型语言，你可以为想要匹配的相应字符串集指定规则；该字符串集可能包含英文语句、email、地址、TeX命令或任何你想搞定的东西。然后你可以问诸如“这个字符串匹配该模式吗？”或“在这个字符串中是否有部分匹配该模式呢？”。你也可以使用 RE以各种方式来修改或分割字符串。正则表达式语言相对小型和受限（功能有限），因此并非所有字符串处理都能用正则表达式完成。当然也有些任务可以用正则表达式完成，不过最终表达式会变得异常复杂。碰到这些情形时，编写 Python 代码进行处理可能反而更好；尽管Python 代码比一个精巧的正则表达式要慢些，但它更易理解。","text":"1.概念：正则表达式（或 RE）是一种小型的、高度专业化的编程语言，在Python中）它内嵌在Python中，并通过 re 模块实现。使用这个小型语言，你可以为想要匹配的相应字符串集指定规则；该字符串集可能包含英文语句、email、地址、TeX命令或任何你想搞定的东西。然后你可以问诸如“这个字符串匹配该模式吗？”或“在这个字符串中是否有部分匹配该模式呢？”。你也可以使用 RE以各种方式来修改或分割字符串。正则表达式语言相对小型和受限（功能有限），因此并非所有字符串处理都能用正则表达式完成。当然也有些任务可以用正则表达式完成，不过最终表达式会变得异常复杂。碰到这些情形时，编写 Python 代码进行处理可能反而更好；尽管Python 代码比一个精巧的正则表达式要慢些，但它更易理解。 2.在正则表达式中， 如下的字符是具有特殊含义的1. (所有字符) ^ $ *(0-N次) +(1-N次) ? (0-1次) &#123; &#125; [ ] \\ | ( ) 1).”[“ 和 “]”。它们常用来指定一个字符类别，所谓字符类别就是你想匹配的一个字符集 2).其它地方的”^”只会简单匹配 “^”字符本身。例[^5] 将匹配除 “5” 之外的任意字符。 3).反斜杠后面可以加不同的字符以表示不同特殊意义。它也可以用于取消所有的元字符 3.RE 函数用法: findall(rule , target [,flag] ) 在目标字符串中查找符合规则的字符串。 match() 决定 RE 是否在字符串刚开始的位置匹配 search() 扫描字符串，找到这个 RE 匹配的位置 findall() 找到 RE 匹配的所有子串，并把它们作为一个列表返回 finditer() 找到 RE 匹配的所有子串，并把它们作为一个迭代器返回 group() 返回被 RE 匹配的字符串 start() 返回匹配开始的位置 end() 返回匹配结束的位置 span() 返回一个元组包含匹配 (开始,结束) 的位置 compile( rule [,flag] )将正则规则编译成一个Pattern对象，以供接下来使用第一个参数是规则式，第二个参数是规则选项。(使用compile加速) 4 : 含义:预定义转义字符集： “\\d” “\\w” “\\s” 等等，它们是以字符’\\’开头，后面接一个特定字符的形式,用来指示一个预定义好的含义 ‘^’ 和’$’ 匹配字符串开头和结尾 ‘.’ 匹配所有字符 除\\n以外 ‘\\d’ 匹配数字 ‘\\D’ 匹配非数字 ‘\\w’ 匹配字母和数字 ‘\\W’ 匹配非英文字母和数字 ‘\\s’ 匹配间隔符 ‘\\S’ 匹配非间隔符 ‘\\A’ 匹配字符串开头 ‘\\Z’ 匹配字符串结尾 ‘\\b’ 只用以匹配单词的词首和词尾。单词被定义为一个字母数字序列，因此词尾就是用空白符或非字母数字符来标示的。(退格) ‘\\B’，它正好同 \\b 相反，只在当前位置不在单词边界时匹配。 5.前向界定与后向界定:‘(?&lt;=…)’ 前向界定:括号中’…’代表你希望匹配的字符串的前面应该出现的字符串。 ‘(?=…)’后向界定 :括号中的’…’代表你希望匹配的字符串后面应该出现的字符串 ‘(?&lt;!..)’前向非界定 :只有当你希望的字符串前面不是’…’的内容时才匹配 ‘(?!...)’后向非界定 :只有当你希望的字符串后面不跟着’…’内容时才匹配。 6.组的基本知识:‘(‘’)’ 无命名组 [a-z]+(\\d+)[a-z]+ ‘(?P&lt;name&gt;…)’ 命名组 (?P&lt;g1&gt;[a-z]+)\\d+(?P=g1) ‘(?P=name)’ 调用已匹配的命名组 ‘\\number’ 通过序号调用已匹配的组正则式中的每个组都有一个序号，序号是按组从左到右，从1开始的数字，你可以通过下面的形式来调用已匹配的组 ( r&quot;(\\d+)([a-z]+)(\\d+)(\\2)(\\1)&quot; ) 123456789101112131415161718192021222324252627282930313233343536373839404142434445# -*- coding:UTF8 -*- import sysreload(sys)sys.setdefaultencoding(&apos;utf-8&apos;)import rhinoscriptsyntax as rs# 正则表达式import restr1 = &quot;abc \\\\ 123 456&quot;print re.findall(&quot;\\\\\\\\&quot;,str1) # 不用r和用r的区print re.findall(r&quot;\\d\\Z&quot;,str1) # 用&quot;r&quot;来定义规则字符串p = re.compile(&apos;(a)b&apos;)m = p.match(&apos;ab&apos;)print m.group()s = &quot;aaa1 22 gg 333 ccc 4444 pppp 55555 666&quot;print re.findall(r&quot;\\b\\d&#123;3&#125;\\b&quot;,s)print re.findall(r&quot;\\b\\d&#123;2,4&#125;\\b&quot;,s)s2 = &quot;aaa111aaa , bbb222 , 333ccc&quot;print re.findall( r&quot;(?&lt;=[a-z]+)\\d+(?=[a-z]+)&quot;,s2 )print re.findall( r&quot;\\d+(?=[a-z]+)&quot;,s2 )## 目标 前面是a-z 1-多次、中间数字1-9 1-多次print re.findall(r&quot;\\d+(?!\\w+)&quot;,s2)#无命名组print re.findall(r&quot;[a-z]+(\\d+)[a-z]+&quot;,s2) # 只返回()里面的s3 = &apos;aaa111aaa,bbb222,333ccc,444ddd444,555eee666,fff777ggg,hhh888hhh&apos;print re.findall(r&quot;([a-z]+)\\d+([a-z]+)&quot;,s3) #返回括号里面的#‘(?P&lt;name&gt;…)’ 命名组print re.findall( r&quot;(?P&lt;g1&gt;[a-z]+)\\d+(?P=g1)&quot;,s3 ) #找出被中间夹有数字的前后同样的字母print re.findall(r&quot;([a-z]+)\\d+\\1&quot;,s3)s4 = &quot;111aaa222aaa111,333bbb444bb33&quot;print re.findall( r&quot;(\\d+)([a-z]+)(\\d+)(\\2)(\\1)&quot;, s4 ) #数字、字母、数字、字母、数字相对称print re.compile(r&quot;(\\d+)([a-z]+)(\\d+)(\\2)(\\1)&quot;).findall(s4)#compile( rule [,flag] ) 使用compile加速s5 = &quot;111,222,aaa,bbb,ccc333,444ddd&quot;print re.compile(r&quot;\\d+\\b&quot;).findall(s5) # \\退格 匹配一个位于开头的数字，没有使用M选项s6 = &quot;123 456\\n789 012\\n345 678&quot;print re.compile(r&quot;^\\d+&quot;,re.M).findall(s6) # 匹配位于(M/多行)开头的数字rcm=re.compile(r&quot;\\d+$&quot;)# 对于’$’来说，没有使用M选项，它将匹配最后一个行尾的数字，即’678’，加上以后，就能匹配三个行尾的数字456 012和678了.print re.compile(r&quot;\\d+$&quot;,re.M).findall(s6) #","categories":[{"name":"python","slug":"python","permalink":"http://blog.fbi.st/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://blog.fbi.st/tags/python/"}]},{"title":"ES2.3.3单机点集群的安装","slug":"ES2.3.3单机点集群的安装","date":"2017-05-20T12:07:31.000Z","updated":"2019-12-26T05:51:46.050Z","comments":true,"path":"2017/05/20/ES2.3.3单机点集群的安装/","link":"","permalink":"http://blog.fbi.st/2017/05/20/ES2.3.3单机点集群的安装/","excerpt":"本文介绍在一个机器上，安装三个节点Elasticsearch，并自动组成集群的方式。","text":"本文介绍在一个机器上，安装三个节点Elasticsearch，并自动组成集群的方式。 第一步：准备工作我们先准备三个目录，分别如下 /usr/es， /usr/es2， /usr/es3 每个目录下，都方式一份默认的 Elasticsearch 2.3.3 解压后的文件。 第二步：修改Elasticsearch 2.3.3的配置文件网上很多的文章都说不用修改文件即可，有个前提是版本是ES 1.x 修改config下的elasticserach.yml文件。这个配置文件非常的重要，也是我们后面在不断深入学习中会一直伴随的一个文件。 主要修改以下内容： 节点名称：node.name： 对外服务的http端口，默认为9200：http.port 节点间交互的tcp端口,默认为9300：transport.tcp.port 集群中master节点的初始列表，这个必须要设置，因为ES 2.X默认是节点单播发现模式，而不是广播发现模式：discovery.zen.ping.unicast.hosts 那么修改完的结果如下： 节点一：1234node.name: node1 http.port: 9200 transport.tcp.port: 9300 discovery.zen.ping.unicast.hosts :[&apos;127.0.0.1&apos;,&apos;127.0.0.1&apos;] 节点二：1234node.name: node2http.port: 9202 transport.tcp.port: 9302discovery.zen.ping.unicast.hosts :[&apos;127.0.0.1&apos;,&apos;127.0.0.1:9203&apos;] 节点三：1234node.name: node3http.port: 9203 transport.tcp.port: 9303discovery.zen.ping.unicast.hosts :[&apos;127.0.0.1&apos;,&apos;127.0.0.1:9202&apos;] 第三步：启动按顺序依次启动ES2,ES3,ES。 1./bin/elasticsearch -d 第四步：验证：新打开一个窗口,输入：1curl -XGET &apos;http://localhost:9200/_cluster/health?pretty=true&apos; 这个时候，我们就看到了上面的内容。123456789101112131415&quot;cluster_name&quot; : &quot;elasticsearch&quot;, //集群名称，默认是elasticserarch&quot;status&quot; : &quot;green&quot;, // 集群的状态，有三个值，green表示正常&quot;timed_out&quot; : false, //是否超时，&quot;number_of_nodes&quot; : 3,//节点个数&quot;number_of_data_nodes&quot; : 3,//数据节点个数&quot;active_primary_shards&quot; : 0,//主分片，因为我们尚未创建索引，所以个数是零，默认是5&quot;active_shards&quot; : 0,//从分片，即复制的分片，默认是一个从复制，所以默认的复制分片也是5.&quot;relocating_shards&quot; : 0,&quot;initializing_shards&quot; : 0,&quot;unassigned_shards&quot; : 0,&quot;delayed_unassigned_shards&quot; : 0,&quot;number_of_pending_tasks&quot; : 0,&quot;number_of_in_flight_fetch&quot; : 0,&quot;task_max_waiting_in_queue_millis&quot; : 0,&quot;active_shards_percent_as_number&quot; : 100.0 看到了这些内容，就表示单机器多节点集群搭建成功，并运行成功！","categories":[{"name":"Elasticsearch非权威指南","slug":"Elasticsearch非权威指南","permalink":"http://blog.fbi.st/categories/Elasticsearch非权威指南/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://blog.fbi.st/tags/Elasticsearch/"}]},{"title":"php装ssh扩展","slug":"php装ssh扩展","date":"2017-05-20T12:07:31.000Z","updated":"2019-12-26T10:08:34.749Z","comments":true,"path":"2017/05/20/php装ssh扩展/","link":"","permalink":"http://blog.fbi.st/2017/05/20/php装ssh扩展/","excerpt":"1.编译安装libssh21234567wget http://www.libssh2.org/download/libssh2-1.2.9.tar.gztar zxvf libssh2-1.2.9.tar.gzcd libssh2-1.2.9./configure &amp;&amp; make &amp;&amp; make install","text":"1.编译安装libssh21234567wget http://www.libssh2.org/download/libssh2-1.2.9.tar.gztar zxvf libssh2-1.2.9.tar.gzcd libssh2-1.2.9./configure &amp;&amp; make &amp;&amp; make install 2.编译安装ssh2(官网http://www.php.net/ssh2)1234567891011wget http://pecl.php.net/get/ssh2-0.11.3.tgztar zxvf ssh2-0.11.3.tgzcd ssh2-0.11.3phpize（如果没有找到该命令，请确定是否安装的是php-dev）./configure --with-ssh2 --with-php-config=/usr/local/php/bin/php-configmake make后有两种方案方法1:1make install 方法21cp modules/ssh2.so /usr/local/php/lib/php/extensions/no-debug-non-zts-20060613/ 然后12echo &quot;extension=ssh2.so&quot; &gt;&gt; /usr/local/php/etc/php.ini # (视php.ini的具体位置确定，也可能是/etc/php.ini)","categories":[{"name":"php","slug":"php","permalink":"http://blog.fbi.st/categories/php/"}],"tags":[{"name":"php","slug":"php","permalink":"http://blog.fbi.st/tags/php/"}]},{"title":"Hadoop+Hbase+ZooKeeper集群搭建方法","slug":"Hadoop+Hbase+ZooKeeper集群搭建方法","date":"2017-05-20T12:07:31.000Z","updated":"2019-12-26T09:08:42.503Z","comments":true,"path":"2017/05/20/Hadoop+Hbase+ZooKeeper集群搭建方法/","link":"","permalink":"http://blog.fbi.st/2017/05/20/Hadoop+Hbase+ZooKeeper集群搭建方法/","excerpt":"hadoop的下载地址hbase的下载地址zookeeper的下载地址 1、 主机配置如下：（添加到/etc/hosts文件里面）12345192.168.0.211 master #（用于集群主机提供hmaster namenode jobtasker服务 ） 192.168.0.212 s1 #(用于集群丛机提供regionsrever datanode tasktacuter服务) 192.168.0.213 s2","text":"hadoop的下载地址hbase的下载地址zookeeper的下载地址 1、 主机配置如下：（添加到/etc/hosts文件里面）12345192.168.0.211 master #（用于集群主机提供hmaster namenode jobtasker服务 ） 192.168.0.212 s1 #(用于集群丛机提供regionsrever datanode tasktacuter服务) 192.168.0.213 s2 2、安装jdk1.6.2.X3、添加java环境变量（/etc/profile），后执行source /etc/profile ,使环境变量立即生效123456export JAVA_HOME=/usr/java/jdk1.6.0_26/ #java 的目录export CLASSPATH=$CLASSPATH:$JAVA_HOME/lib:$JAVA_HOME/jre/lib export PATH=$JAVA_HOME/bin:$PATH:$CATALINA_HOME/bin export HADOOP_HOME=/home/hadoop/hadoop export HBASE_HOME=/home/hadoop/hbase PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HBASE_HOME/bin 4、在三台电脑上添加hadoop用户1useradd hadoop 5、在/home/hadoop/.bashrc添加变量 (将hadoop hbase的配置文件放到hadoop安装包根目录文件下，目的在于以后升级hadoop和hbase的时候不用重新导入配置文件)*12export HADOOP_CONF_DIR=/home/hadoop/hadoop-config export HBASE_CONF_DIR=/home/hadoop/hbase-config 6、将hadoop hbase zookepper的安装包解压到/home/hadoop/下，并重命名为hadoop hbase zookepper，在home/hadoop/下建立hadoop-config和hbase-config文件夹，并且将home/hadoop/hadoop/conf下的masters、slaves、core-site、mapred-sit、hdfs-site、hadoop-env拷贝到此文件夹，将home/hadoop/hbase/conf下的hbase-site和hbase-env.sh拷贝到次文件夹。 7、修改masters、slaves文件： 分别为 master 和s1与s2 8、修改hadoop-env.sh的变量：12export JAVA_HOME=/usr/java/jdk1.6.0_26/ export HADOOP_PID_DIR=/home/hadoop/hadoop/tmp ##9、修改core-site.xml123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;hdfs://master:9000&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 修改mapred-site.xml123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapred.job.tracker&lt;/name&gt; &lt;value&gt;hdfs://master:9001/&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 修改hdfs-site.xml（name和data文件夹不要手动建立）1234567891011121314&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.name.dir&lt;/name&gt; &lt;value&gt;/home/hadoop/hadoop/name&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.data.dir&lt;/name&gt; &lt;value&gt;/home/hadoop/hadoop/data/&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;3&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 10、设置master, s1, s2机几台器之间无密码访问：11、复制目录至集群丛机12scp -r /home/hadoop/hadoop s1:/home/hadoopscp -r /home/hadoop/hadoop s2:/home/hadoop 12、切换到/home/hadoop/hadoop目录下执行 1bin/hadoop namenode -format (格式化master主机生成name data tmp等文件夹) 13、启动namenode执行1bin/start-dfs.sh 使用jps命令查看namenode、secondnamenode是否正常启动：ie里面输入http://master:50070 查看namenode的相关配置信息、运行状态和日志文件 14、启动mapred执行1bin/start-mapred.sh 使用jps命令查看nomenode、secondnamenode是否正常启动：ie里面输入http://master:50030 查看jobtasker的相关配置信息、运行状态和日志文件 hbase+zookeeper集群搭建：1、复制目录修改文件将/home/hadoop/hadoop/conf/目录下的hbase-site.xml、regionserver和hbase-env.sh拷贝到/home/hadoop/hbase-config/目录下；编辑hbase-site.xml配置文件，如下： 123456789101112131415161718192021222324&lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://master:9000/hbase&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.master&lt;/name&gt; &lt;value&gt;master&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; &lt;value&gt;s1,s2&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;zookeeper.session.timeout&lt;/name&gt; &lt;value&gt;60000000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.property.clientport&lt;/name&gt; &lt;value&gt;2222&lt;/value&gt; &lt;/property&gt; 2、编辑regionserver文件12S1 S2 3、编辑hbase-env.xml文件1234567export JAVA_HOME=/usr/java/jdk1.6.0_26/ export CLASSPATH=$CLASSPATH:$JAVA_HOME/lib:$JAVA_HOME/jre/lib export PATH=$JAVA_HOME/bin:$PATH:$CATALINA_HOME/bin export HADOOP_HOME=/home/hadoop/hadoop export HBASE_HOME=/home/hadoop/hbase export HBASE_MANAGES_ZK=true export PATH=$PATH:/home/hadoop/hbase/bin 4、复制文件到集群丛机12scp -r /home/hadoop/hbase s1:/home/hadoop scp -r /home/hadoop/hbase s2:/home/hadoop 5、进入/home/hadoop/zookeeper/conf/中 (1)1cp zoo_sample.cfg zoo.cfg (2)1vim zoo.cfg 如下： 1234567891011121314# The number of milliseconds of each tick tickTime=2000 # The number of ticks that the initial # synchronization phase can take initLimit=10 # The number of ticks that can pass between # sending a request and getting an acknowledgement syncLimit=5 # the directory where the snapshot is stored. dataDir=/home/hadoop/zookeeper/data # the port at which the clients will connect clientPort=2181 server.1=s1:2888:3888 server.2=s2:2888:3888 (3)1touch myid *编辑：1（此序号设置和zoo.cfg里面的server设置要对应)12scp -r /home/hadoop/zookeeper s1:/home/hadoop scp -r /home/hadoop/zookeeper s2:/home/hadoop 4）在所有的节点执行1chown -R hadoop.hadoop /home/hadoop 启动hbase集群：（1）12（2）执行```jps```显示Hmaster是否启动（3）执行```bin/hbase shell (4)123&gt;create &apos;t1&apos; t2&apos;&apos; &apos;t3&apos;#(测试利用hmaster插入数据) &gt;list #（显示已经插入的数据） &gt;t1+t2+t3 输入：http://master:60010 延伸：Hadoop 页面监控信息网址列表 将Hadoop中可能用到的网页地址list到下面，方便查阅： http://master:50030 查看MapReduce上的jobtracker（在启动了hdfs和MapReduce之后查阅） http://master:50060 查看MapReduce上的tasktracker（在启动了hdfs和MapReduce之后查阅） http://master:50070 查看HDFS上的节点信息（在启动了HDFS之后查阅） http://master:60010/master.jsp 查看master连点信息 （在启动了HDFS、MapReduce、ZooKeeper和HBase之后查阅） http://master:60030/regionserver.jsp 查看regionserver信息（在启动了HDFS、MapReduce、ZooKeeper和HBase之后查阅） http://master:60010/zk.jsp 查看zookeeper信息（在启动了HDFS、MapReduce、ZooKeeper和HBase之后查阅）","categories":[{"name":"数据库","slug":"数据库","permalink":"http://blog.fbi.st/categories/数据库/"}],"tags":[{"name":"Hadoop","slug":"Hadoop","permalink":"http://blog.fbi.st/tags/Hadoop/"}]},{"title":"如何更改MySQL的datadir目录","slug":"如何更改MySQL的datadir目录","date":"2017-05-20T12:07:31.000Z","updated":"2019-12-26T09:56:21.126Z","comments":true,"path":"2017/05/20/如何更改MySQL的datadir目录/","link":"","permalink":"http://blog.fbi.st/2017/05/20/如何更改MySQL的datadir目录/","excerpt":"本人小白，遇到的问题也是小白的问题。写下心得是希望对其他的小白有所帮助。这两天在倒腾一个比较大的数据库，（Ubuntu环境）发现虚拟机硬盘不够了，所以添加了一块。但是加了硬盘又涉及到了修改mysql数据库的datadir。本以为只是简单的修改一下配置文件中的","text":"本人小白，遇到的问题也是小白的问题。写下心得是希望对其他的小白有所帮助。这两天在倒腾一个比较大的数据库，（Ubuntu环境）发现虚拟机硬盘不够了，所以添加了一块。但是加了硬盘又涉及到了修改mysql数据库的datadir。本以为只是简单的修改一下配置文件中的 1datadir=“目录” 就可以了。没想到修改后Mysql居然打不开了。于是又开始求助万能的百度:如何修改Mysql的datadir目录。结果还是有很多，但基本上是转载的同一篇文章。说是要修改1socket=/var/lib/mysql/mysql.sock //mysql配置文件my.cnf中的这个值 还有修改mysql文件的所有者、权限等等。。ps：这一步还是有必要的。还要修改一堆文件。比如/etc/init.d/mysqld 文件等等。秉着宁错过不放过的原则，我改改改。。然而还是没有什么用。。反而把配置文件弄得乱七八糟。。这时候，大神同事给了个建议，直接卸载了重装吧。然后就百度了一下：Ubuntu如何干净的卸载mysql?，得到方法如下：1234567891、删除 mysqlsudo apt-get autoremove --purge mysql-server-5.5sudo apt-get remove mysql-serversudo apt-get autoremove mysql-serversudo apt-get remove mysql-common (非常重要)2、清理残留数据dpkg -l |grep ^rc|awk &apos;&#123;print $2&#125;&apos; |sudo xargs dpkg -P在最后清理数据的时候会弹出一个对话框，问你是否要清除数据，清除就可以完全卸载了。 然后又百度了一下：Ubuntu安装mysql时如何修改datadir？稍稍的改了一下找寻目标，结果就发现了一个和之前不一样的答案。 #####关于如何更改datadir目录的问题：ubuntu默认安装mysql的时候，会将datadir设置为/var/lib/mysql下面，但是我们大多数时候都需要指定一个我们准备好的方便查找的目录为数据存储目录，我们可以在my.cnf下面更改datadir这一行，将’=‘后边的目录更改成我们自己的目录即可。 例如：我将datadir改成/data下，则在my.cnf中做如下更改，在[mysqld]段123port = 3306basedir = /usrdatadir = /data/mysql 更改完成保存退出，可以重启mysql服务了，不知道您的服务器会不会报错，我的反正mysql是起不来了。只要将datadir换回来就能启动。出现这个问题的原因是在ubuntu中存在一个apparmor的服务。 这个服务主要作用是主要的作用是设置某个可执行程序的访问控制权限，可以限制程序 读/写某个目录/文件，打开/读/写网络端口等等。(原来，我们虽然讲新的目录所有者改为了mysql,但我们没有告诉mysql要给新的目录什么权限，于是就悲剧了) 他的配置文件在/etc/apparmor.d/中，在这里我们可以看到一个usr.sbin.mysqld的配置文件，打开看一下就明白了。 我们的日志路径、pid路径等等都存放在这里，所以我们要改datadir路径，这里也需要做更改，要更改log路径同样也要在这里更改。更改后配置如下：123456/logs/mysql/mysql.log rw,/logs/mysql/mysql.err.log rw,/data/mysql/ r,/data/mysql/** rwk,/logs/mysql/ r,/logs/mysql/* rw, 这是我更改过的路径。更改完成以后，因为这是一个服务，所以我们需要重启一下这个服务。1/etc/init.d/apparmor restart 这里基本上不会存在问题了，(我就是在这里重启了一下服务器，就OK了)，如果还是无法启动你的mysql，那么请使用如下命令1mysql_install_db --datadir=/data/mysql 查看一下是不是有报错信息，根据错误排查一下。 最终按照这个方法解决了问题。真是多谢前辈。最后本人做个总结，只作为一种尝试解决方案： ######将mysql默认的datadir目录”/var/lib/mysql”改为 “/home/mysql_data” 1、关掉数据库1sudo /etc/init.d/mysql stop 2、因为我们指定的数据库文件目录为/home/mysql_data12345cd /home //打开homemkdir mysql_data //创建目录chown mysql:mysql mysql_data //并修改其拥有者及所属群组为mysql:mysql.命令//修改mysql配置文件my.cnf：将 datadir=/var/lib/mysql 改为 datadir=/home/mysql_data 3、修改ubuntu中的安全设置1234567sudo gedit /etc/apparmor.d/usr.sbin.mysqld 在这个文件里面加入权限设定，将原来的/var/lib/mysql/ r,/var/lib/mysql/** rwk,更换成(或直接添加)/home/mysql_data/mysql/ r,/home/mysql_data/mysql/** rwk, 4、重新初始化数据文件：执行1sudo mysql_install_data 5、启动mysql数据库服务(或重启服务器)：1sudo /etc/init.d/mysql start 这个方法中最值得一提是修改/etc/apparmor.d/usr.sbin.mysqld这个文件，改变应用程序的权限。这种配置权限方式让我这个小白对linux权限的理解又深刻了不少。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://blog.fbi.st/categories/数据库/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://blog.fbi.st/tags/Mysql/"},{"name":"数据库","slug":"数据库","permalink":"http://blog.fbi.st/tags/数据库/"},{"name":"Linux","slug":"Linux","permalink":"http://blog.fbi.st/tags/Linux/"}]},{"title":"用php验证一个字符串是否符合4则运算","slug":"用php验证一个字符串是否符合4则运算","date":"2017-05-20T12:07:31.000Z","updated":"2019-12-26T10:04:57.446Z","comments":true,"path":"2017/05/20/用php验证一个字符串是否符合4则运算/","link":"","permalink":"http://blog.fbi.st/2017/05/20/用php验证一个字符串是否符合4则运算/","excerpt":"实际项目中遇到的一个问题。如何实现Google高级查询的字段解析功能。 例如：1$expression = &quot;(张三-(赵六|田七))+朱八&quot;; 需要解析成：1and(张三，朱八) not( or(赵六，田七)) 解决思路是：先判断是否符合+|-三种运算语法。如果符合，再将内容解析转换为逆波兰式。最后拼接查询语句。 检测代码如下：","text":"实际项目中遇到的一个问题。如何实现Google高级查询的字段解析功能。 例如：1$expression = &quot;(张三-(赵六|田七))+朱八&quot;; 需要解析成：1and(张三，朱八) not( or(赵六，田七)) 解决思路是：先判断是否符合+|-三种运算语法。如果符合，再将内容解析转换为逆波兰式。最后拼接查询语句。 检测代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586 /** * 验证关键字是不是符合四则运算 * @return bool */ private function check_bool($keyword) &#123; $k = $keyword != \"\" ? $keyword : die('关键字不能为空'); //剔除空白字符 str_replace(\" \", \"\", $k); //符号连续的情况 if (preg_match(\"/[\\+\\-\\|]&#123;2,&#125;/\", $k)) &#123; return false; &#125;; //空括号的情况 if (preg_match(\"/\\(\\)/\", $k)) &#123; return false; &#125; //括号不配对 $stack = []; for ($i = 0; $i &lt; strlen($k); $i++) &#123; $item = substr($k, $i, 1); if ('(' === $item) &#123; array_push($stack, '('); &#125; else if (')' === $item) &#123; if (count($stack) &gt; 0) &#123; array_pop($stack); &#125; else &#123; return false; &#125; &#125; &#125; if (0 !== count($stack)) &#123; return false; &#125; // 错误情况，(后面是运算符 if (preg_match(\"/\\([\\+\\-\\|]/\", $k)) &#123; return false; &#125; // 错误情况，)前面是运算符 if (preg_match(\"/[\\+\\-\\|]\\)/\", $k)) &#123; return false; &#125; // 错误情况，(前面不是运算符 if (preg_match(\"/[^\\+\\-\\|]\\(/\", $k)) &#123; return false; &#125; // 错误情况，)后面不是运算符 if (preg_match(\"/\\)[^\\+\\-\\|]/\", $k)) &#123; return false; &#125; //没有除了符号外的关键字 //切割 $tmp_str = preg_replace('/[\\(\\)\\+\\-\\|]&#123;1,&#125;/', '`', $k); $arr = explode('`', $tmp_str); //清除空的数量 $keys = array_keys($arr, ''); if (!empty($keys)) &#123; foreach ($keys as $key) &#123; unset($arr[$key]); &#125; &#125; //如果删除后只剩一个， if (count($arr) &lt;= 1) &#123; return false; &#125; for ($i = 0; $i &lt; count($arr); $i++) &#123; if ((1 &lt; $i) &amp;&amp; ($i &lt; count($arr) - 1)) &#123; if (preg_match(\"/^[\\x&#123;4e00&#125;-\\x&#123;9fa5&#125;a-zA-Z0-9]+$/\", $arr[$i]) || $arr[$i] == '') &#123; return false; &#125; &#125; else &#123; //var_dump($arr[$i]); if (preg_match(\"/^[\\x&#123;4e00&#125;-\\x&#123;9fa5&#125;a-zA-Z0-9]+$/\", $arr[$i]) &amp;&amp; $arr[$i] != '') &#123; return false; &#125; &#125; &#125; return true;&#125; //测试实例$expression = \"(A+(BXXX|CXXX)-EXXX+F)-111-211111\";//$expression = \"(张三-(李四-王五)-(赵六|田七))-朱八\";var_dump(check_bool($expression));","categories":[{"name":"php","slug":"php","permalink":"http://blog.fbi.st/categories/php/"}],"tags":[{"name":"php","slug":"php","permalink":"http://blog.fbi.st/tags/php/"}]},{"title":"elasticsearch各种组件的安装_head_kopf_bigdesk","slug":"elasticsearch及各种组件的安装","date":"2017-05-20T12:07:31.000Z","updated":"2019-12-26T10:05:51.014Z","comments":true,"path":"2017/05/20/elasticsearch及各种组件的安装/","link":"","permalink":"http://blog.fbi.st/2017/05/20/elasticsearch及各种组件的安装/","excerpt":"一、安装Elasticsearch-Head1.插件安装方式（推荐）在Elasticsearch目录下1$/bin/plugin install mobz/elasticsearch-head 如果提示1ERROR: unknown command [-install]. Use [-h] option to list available commands 是因为好像2.0以上的版本-install 变成了 install了。 1elasticsearch/bin/plugin install mobz/elasticsearch-head","text":"一、安装Elasticsearch-Head1.插件安装方式（推荐）在Elasticsearch目录下1$/bin/plugin install mobz/elasticsearch-head 如果提示1ERROR: unknown command [-install]. Use [-h] option to list available commands 是因为好像2.0以上的版本-install 变成了 install了。 1elasticsearch/bin/plugin install mobz/elasticsearch-head 2.下载安装方式从https://github.com/mobz/elasticsearch-head下载ZIP包。1sudo ./plugin install file:///Users/Richard/Downloads/elasticsearch-head-master.zip 二、重启Elasticsearch。访问。访问地址是： http://{你的ip地址}:9200/_plugin/head/ http 端口默认是: 9200 。 二、安装Elasticsearch-kopf1.插件安装方式（推荐）在Elasticsearch目录下 1./bin/plugin install lmenezes/elasticsearch-kopf/&#123;branch|version&#125; 支持版本表| elasticsearch | version branch | latest version| — | — | — |0.90.X | 0.90 | v0.901.X | 1.0 | v1.6.12.X | 2.0 | v2.1.1 2.下载安装方式从https://github.com/lmenezes/elasticsearch-kopf下载ZIP包。12345678sudo ./plugin install file:///dir/elasticsearch-kopf.zip``` ## 三、安装Elasticsearch-Bigdesk### 1.插件安装方式（推荐）在Elasticsearch目录下 ./bin/plugin install hlstudio/bigdesk122.下载安装方式从[https://github.com/hlstudio/bigdesk](https://github.com/hlstudio/bigdesk)下载ZIP包。 sudo ./plugin install file:///dir/elasticsearch-kopf.zip`","categories":[{"name":"Elasticsearch非权威指南","slug":"Elasticsearch非权威指南","permalink":"http://blog.fbi.st/categories/Elasticsearch非权威指南/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://blog.fbi.st/tags/Elasticsearch/"}]},{"title":"简述应用程序接口(API)","slug":"简述应用程序接口(API)","date":"2017-05-20T12:07:31.000Z","updated":"2019-12-27T01:54:17.633Z","comments":true,"path":"2017/05/20/简述应用程序接口(API)/","link":"","permalink":"http://blog.fbi.st/2017/05/20/简述应用程序接口(API)/","excerpt":"写下这个文章的原因是,我发现身边一些的朋友可能是因为之前没有接触过API,以至于对API有些不解和抵触.因为微信开发/地图定位/各种大数据的信息查询,让接口(api)成为了一个非常常用的工具.这篇文章是我自己的一些理解,由于本人也是个小白,肯定有很多地方不到位,希望能指出.首先,我们从API是什么开始说. 1.API是什么? 维基百科的解释是:应用程序接口 (Application Programming Interface 简称:API)为：“‘电脑操作系统（Operating system）’或‘程序库’提供给应用程序调用使用的代码”。其主要目的是让应用程序开发人员得以调用一组例程)功能，而无须考虑其底层的源代码为何、或理解其内部工作机制的细节。 API本身是抽象&amp;action=edit&amp;redlink=1)的，它仅定义了一个接口)，而不涉及应用程序在实际实现过程中的具体操作。","text":"写下这个文章的原因是,我发现身边一些的朋友可能是因为之前没有接触过API,以至于对API有些不解和抵触.因为微信开发/地图定位/各种大数据的信息查询,让接口(api)成为了一个非常常用的工具.这篇文章是我自己的一些理解,由于本人也是个小白,肯定有很多地方不到位,希望能指出.首先,我们从API是什么开始说. 1.API是什么? 维基百科的解释是:应用程序接口 (Application Programming Interface 简称:API)为：“‘电脑操作系统（Operating system）’或‘程序库’提供给应用程序调用使用的代码”。其主要目的是让应用程序开发人员得以调用一组例程)功能，而无须考虑其底层的源代码为何、或理解其内部工作机制的细节。 API本身是抽象&amp;action=edit&amp;redlink=1)的，它仅定义了一个接口)，而不涉及应用程序在实际实现过程中的具体操作。 2.简单举例简而言之接口就是一个抽象的,不需要考虑内部细节的东西.你拿来用就可以了.这么讲可能抽象了一些,我们举个例子: 以百度地图IP定位的API为例: 服务地址:http://api.map.baidu.com/location/ip 接口参数: 返回结果: 1234567891011121314151617&#123; address: &quot;CN|北京|北京|None|CHINANET|1|None&quot;, #地址 content: #详细内容 &#123; address: &quot;北京市&quot;, #简要地址 address_detail: #详细地址信息 &#123; city: &quot;北京市&quot;, #城市 city_code: 131, #百度城市代码 district: &quot;&quot;, #区县 province: &quot;北京市&quot;, #省份 street: &quot;&quot;, #街道 street_number: &quot;&quot; #门址 &#125;, point: #百度经纬度坐标值 &#123; x: &quot;116.39564504&quot;, y: &quot;39.92998578&quot; &#125; &#125;, status: 0 #返回状态码 &#125; 那么,服务地址/接口参数/返回结果分别是什么意思呢? 我们一一来理解:服务地址: 即我们需要数据请求的页面地址. 请求参数： 有的时候我们不只从接口上取值,我们还需要用一种特殊的方式告诉服务器,我们需要什么数据,你给我们需要的就可以了,别瞎给.这种方式通常是URL传参的形式.比如百度的这个api就可以这样传. 1http://api.map.baidu.com/location/ip?ak=E4805d16520de693a3fe707cdc962045&amp;ip=202.198.16.3&amp;coor=bd09ll 通过url,我们告诉百度,我们的ak(access key)是:E48....62045,我们要定位的ip是:202.198.16.3,coor是:bd09ll(告诉百度我们需要经纬坐标). 这就是一中最最常用的使用API的方式. 返回结果 上面我们通过URL传参的方式告诉了百度服务器,我们需要的是IP为202.198.16.3的位置信息,而且需要经纬坐标值(coor=bd09ll),并且我们的Ak值是对的, 这时候,百度就会输出一个结果在页面里,通常是JSON字符串的形式.如: 1234567891011121314151617&#123; address: \"CN|吉林|长春|None|CERNET|1|None\", content: &#123; address: \"吉林省长春市\", address_detail: &#123; city: \"长春市\", city_code: 53, district: \"\", province: \"吉林省\", street: \"\", street_number: \"\" &#125;, point: &#123; x: \"125.31364243\", y: \"43.89833761\" &#125; &#125;, status: 0 &#125; 我们可以通过读取url页面的形式来获取返回的json字符串.再应用到我们的项目中. 上述就是一个最简单的API使用,也是最本质/常用的一种.(传值和取值) 从上面的例子中,我们就可以知道,为什么API不需要考虑程序的内部细节了吧?其实它就好像一个封装好的电池,我们放到卡槽里用就行了,不需要去了解内部结构. 3.写一个简单的API对于大型的API内部封装的算法是非常复杂的. 但它的原理并不难,我们自己就可以尝试着写上一个小小的API.这里我给个例子:123456789101112131415161718192021222324&lt;?php#假设存为index.php到根目录header ('content-type:text/html;charset=utf-8');$con = mysql_connect(\"localhost\",\"root\",\"root\");if (!$con) &#123; die('Could not connect: ' . mysql_error()); &#125;mysql_select_db('chaxun',$con); $token=isset($_GET['token'])?$_GET['token']:\"1\";if ($token==123) &#123; $sql=\"SELECT * FROM data;\"; $result = mysql_query($sql); while($row = mysql_fetch_array($result, MYSQL_ASSOC))&#123; $rst[]=$row; &#125; $rst_json = json_encode($rst); echo $rst_json;&#125;else&#123; echo \"token错误!\";&#125;mysql_close();?&gt; 上面的例子, 我们API服务地址就是:http://localhost/index.php 接口参数我们需要传一个token=123 返回结果就是一个查询数据库的结果,转换的json字符串. 完整的url拼起来就是:http://localhost/index.php?token=123 看吧,其实写个接口就这么简单. 好困,睡了,明天再来补完整.","categories":[{"name":"php","slug":"php","permalink":"http://blog.fbi.st/categories/php/"}],"tags":[{"name":"php","slug":"php","permalink":"http://blog.fbi.st/tags/php/"}]},{"title":"Elasticsearch名词解释","slug":"ES一些名词的解释","date":"2017-05-20T12:07:31.000Z","updated":"2019-12-26T10:07:07.247Z","comments":true,"path":"2017/05/20/ES一些名词的解释/","link":"","permalink":"http://blog.fbi.st/2017/05/20/ES一些名词的解释/","excerpt":"本来这个打算后面再来写的，看到简书上一个朋友归纳好了，我就直接借过来了。 数据层面： Index：Elasticsearch用来存储数据的逻辑区域，它类似于关系型数据库中的db概念。一个index可以在一个或者多个shard上面，同时一个shard也可能会有多个replicas。","text":"本来这个打算后面再来写的，看到简书上一个朋友归纳好了，我就直接借过来了。 数据层面： Index：Elasticsearch用来存储数据的逻辑区域，它类似于关系型数据库中的db概念。一个index可以在一个或者多个shard上面，同时一个shard也可能会有多个replicas。 Document type：为了查询需要，一个index可能会有多种类型document，也就是会有多个 document type，但需要注意，不同的document type里面同名的field一定要是相同类型的。 Document：Elasticsearch里面存储的实体数据，类似于关系数据中一个table里面的一行数据。 field：document由多个field组成，不同类型的document里面同名的field一定具有相同的类型。 multivalued： document里面field可以重复出现，也就是一个field会有多个值，即multivalued。 Mapping：存储field的相关映射信息，不同document type会有不同的mapping。 对于熟悉MySQL的童鞋，我们只需要大概认为Index就是一个database，document就是一行数据，field就是table的column，mapping就是table的定义，而document type就是一个table就可以了。 《elasticsearch学习笔记》目录本笔记欢迎转载，欢迎分享，转载分享不用通知作者。不过，如果可以的话希望能注明出处，看完文章还能点个赞。","categories":[{"name":"Elasticsearch非权威指南","slug":"Elasticsearch非权威指南","permalink":"http://blog.fbi.st/categories/Elasticsearch非权威指南/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://blog.fbi.st/tags/Elasticsearch/"}]},{"title":"MySQL数据库优化-总结","slug":"MySQL数据库优化-总结","date":"2016-07-20T02:43:45.000Z","updated":"2019-12-26T10:08:15.238Z","comments":true,"path":"2016/07/20/MySQL数据库优化-总结/","link":"","permalink":"http://blog.fbi.st/2016/07/20/MySQL数据库优化-总结/","excerpt":"面试时遇到的问题：千万级的mysql数据库如何优化？作为一个刚入门的phper,遇到这个问题时,我还是压力山大的.还好有一个周末的时间来学习.本文就是这周末三天的整理总结.","text":"面试时遇到的问题：千万级的mysql数据库如何优化？作为一个刚入门的phper,遇到这个问题时,我还是压力山大的.还好有一个周末的时间来学习.本文就是这周末三天的整理总结. 方案一:缓存通过redis或memcache,添加缓存服务器.原理:将经常查询的内容自动添加到缓存,访问量低的通过正常查询获得,可以让绝大多数的内容从内存中自动访问. ridis和memcache的区别: 1 Redis不仅仅支持简单的k/v类型的数据，同时还提供list，set，hash等数据结构的存储。 2 Redis支持数据的备份，即master-slave模式的数据备份。 3 Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用。 方案二:添加索引通过对常用字段添加索引的办法可以极大的提高查询的效率.注意事项: 首先应考虑在 where 及 order by 涉及的列上建立索引。///禁用排名,oder by null 可以在 num 上设置默认值 0,确保表中 num 列没有 null 值。 不要写一些没有意义的查询. 用 exists 代替 in 是一个好的选择.如: select num from a where num in(select num from b);可以用select num from a where exists(select 1 from b where num=a.num);来代替. 索引并不是越多越好，索引固然可以提高相应的 select 的效率，但同时也降低了 insert 及 update 的效率，因为 insert 或 update 时有可能会重建索引，所以怎样建索引需要慎重考虑，视具体情况而定。一个表的索引数最好不要超过 6 个，若太多则应考虑一些不常使用到的列上建的索引是否有必要。 尽量使用数字型字段，若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能,并增加存储开销。这是因为引擎在处理查询和连接时会逐个比较字符串中每一个字符，而对于数字型而言 只需要比较一次就够了。 尽可能的使用 varchar/nvarchar代替 char/nchar, 因为首先变长字段存储空间小， 可以节省存储空间， 其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些。 不要使用 select * from t,用具体的字段列表代替“*”,不要返回用不到的任何字段。 避免全表扫描: 避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描。 select id from t where name like &#39;%c%&#39;;也将导致全表扫描。 如果在 where 子句中使用参数，也会导致全表扫描.如:select id from t where num=@num ;可以改为强制查询使用索引:select id from t with(index(索引名)) where num=@num ; 在 where 子句中对字段进行表达式操作， 这将导致引擎放弃使用索引而进行全表扫描。如:select id from t where num/2=100; 在 where 子句中对字段进行函数操作，这将导致引擎放弃使用索引而进行全表扫描。如：select id from t where substring(name,1,3)=&#39;abc&#39;;#name 以 abc 开头的 id 方案三:水平分库/分表原理:一个1000多万条记录的用户表user,查询起来非常之慢，分表的做法是将其散列到100个表中，分别从user_0到user_99，然后根据userId分发记录到这些表中. 方案四:Sphinx等索引工具原理:Sphinx工具是一个基于SQL的索引检索引擎.原理是将SQL中的数据建立索引,php通过API的方式从Sphinx中获得检索的值.php不直接通过mysql取值. Sphinx的特性（优、缺点）优点： 高速索引 (在新款CPU上,近10 MB/秒); 高速搜索 (2-4G的文本量中平均查询速度不到0.1秒); 高可用性 (单CPU上最大可支持100 GB的文本,100M文档); 提供良好的相关性排名 支持分布式搜索; 提供文档摘要生成; 提供从MySQL内部的插件式存储引擎上搜索 支持布尔,短语, 和近义词查询; 支持每个文档多个全文检索域(默认最大32个); 支持每个文档多属性; 支持断词; 支持单字节编码与UTF-8编码; 支持多字段的检索域 支持MySQL（MYISAM和INNODB）和Postgres数据库 支持windows, linux, unix, mac等平台 缺点： 必须要有主键 主键必须为整型 不负责数据存储 配置不灵活 方案五:读写分离原理：通过物理的方式来提升mysql的性能.…未完待续","categories":[{"name":"数据库","slug":"数据库","permalink":"http://blog.fbi.st/categories/数据库/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://blog.fbi.st/tags/Mysql/"},{"name":"数据库","slug":"数据库","permalink":"http://blog.fbi.st/tags/数据库/"}]},{"title":"11个提问频率最高的PHP面试题","slug":"11个提问频率最高的PHP面试题","date":"2016-05-20T12:07:31.000Z","updated":"2019-12-27T01:54:17.631Z","comments":true,"path":"2016/05/20/11个提问频率最高的PHP面试题/","link":"","permalink":"http://blog.fbi.st/2016/05/20/11个提问频率最高的PHP面试题/","excerpt":"问题：请用最简单的语言告诉我PHP是什么？回答：PHP全称：Hypertext Preprocessor，是一种用来开发动态网站的服务器脚本语言。","text":"问题：请用最简单的语言告诉我PHP是什么？回答：PHP全称：Hypertext Preprocessor，是一种用来开发动态网站的服务器脚本语言。 问题：什么是MVC？回答：MVC由Model（模型）, View（视图）和Controller（控制器）组成，PHP MVC可以更高效地管理好3个不同层的PHP代码。Model：数据信息存取层。View：view层负责将应用的数据以特定的方式展现在界面上。Controller：通常控制器负责从视图读取数据，控制用户输入，并向模型发送数据。 问题：在页面中引用CSS有几种方式？回答：在页面中使用CSS有3中方式：引用外部CSS文件内部定义Style样式内联样式 问题：PHP支持多继承吗？回答：不可以。PHP类只能继承一个父类，并用关键字“extends”标识。 问题：请问PHP中echo和print有什么区别？这两个看起来很相似，因为它们都是将一些值打印在屏幕上。但是echo和print的本质区别在于：echo用来输出字符串，显示多个值的时候可以用逗号隔开。只支持基本类型，print不仅可以打印字符串值，而且可以打印函数的返回值。 问题：请问GET和POST方法有什么区别？回答：我们再网页上填写的表单信息都可以通过这两个方法将数据传递到服务器上，当我们使用GET方法是，所有的信息都会出现在URL地址中，并且使用GET方法最多只能传递1024个字符，所以如果在传输量小或者安全性不那么重要的情况下可以使用GET方法。说到POST方法，最多可以传输2MB字节的数据，而且可以根据需要调节。 问题：PHP中获取图像尺寸大小的方法是什么？回答：getimagesize () 获取图片的尺寸Imagesx () 获取图片的宽度Imagesy () 获取图片的高度 问题：PHP中的PEAR是什么？回答：PEAR也就是为PHP扩展与应用库（PHP Extension and Application Repository），它是一个PHP扩展及应用的一个代码仓库。 问题：如何用PHP和MySQL上传视频？回答：我们可以在数据库中存放视频的地址，而不需要将真正的视频数据存在数据库中。可以将视频数据存放在服务器的指定文件夹下，上传的默认大小是2MB，但是我们也可以在php.ini文件中修改max_file size选项来改变。 问题：PHP中的错误类型有哪些？回答：PHP中遇到的错误类型大致有3类。提示：这都是一些非常正常的信息，而非重大的错误，有些甚至不会展示给用户。比如访问不存在的变量。警告：这是有点严重的错误，将会把警告信息展示给用户，但不会影响代码的输出，比如包含一些不存在的文件。错误：这是真正的严重错误，比如访问不存在的PHP类。 ###问题：如何在PHP中定义常量？回答：PHP中使用Define () 来定义常量。define (“Newconstant”, 30); ###问题：如何不使用submit按钮来提交表单？如果我们不想用submit按钮来提交表单，我们也可以用超链接来提交，我们可以这样写代码：","categories":[{"name":"php","slug":"php","permalink":"http://blog.fbi.st/categories/php/"}],"tags":[{"name":"php","slug":"php","permalink":"http://blog.fbi.st/tags/php/"}]}]}